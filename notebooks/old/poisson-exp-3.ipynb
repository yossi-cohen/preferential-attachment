{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e35762d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "%run lib.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023fb420",
   "metadata": {},
   "source": [
    "## Experiment 3.1: Compute prediction error\n",
    "So far, we computed the error (MSE / MAE) of λ comparing the learned one with the actual one.  \n",
    "In this experiment, we test the error in prediction. So,\n",
    "\n",
    "### Part I\n",
    "- M=256 sample points, generating histogram H of size K; H[k] = number of samples in bin k, i.e., count how many sample points. Therefore K is computed, but will be small for typical values of λ.\n",
    "- λ = 0.5 ... 1.5\n",
    "- N = 10K\n",
    "\n",
    "Let V = (H[k] - M * Poisson(λ,k))\n",
    "\n",
    "Then V is parameterized by\n",
    "\n",
    "k: the current bin\n",
    "\n",
    "i = 1,...,N: sample number\n",
    "\n",
    "All computation must include therefore K*N values of V.\n",
    "\n",
    "**Objective**: compute MAE(V), MSE(V), MEAN_BIAS(V), with respect to all these values.\n",
    "\n",
    "### Part II\n",
    "Repeat with λ computed by the expectation of the sample, i.e., $\\sum_{k=0}^{K}\\; \\frac{k*H[k]}{M}$\n",
    "\n",
    "### Part III\n",
    "- Combine Part I and Part II, to find out which is better; ours should be. We need a single table/graph/plot.\n",
    "\n",
    "\n",
    "- Show that the expectation of the sample, gives a biased estimate, and that ours does not.\n",
    "\n",
    "  To do so: Same data as stage I, but NO LEARNING. Use N=10,000, compute λ by its expectation; \n",
    "  \n",
    "  compare with the λ you selected at random, and show that there is bias between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "578bd488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating data (M=1024, N=10000) ... histogram shape: (7500, 10)\n",
      "\n",
      "experiment_3_1_part_I (prediced λ)\n",
      "fitting dnn model ... duration: 21 sec.\n",
      "predicting lambdas ... sqrt_mse(λ): 0.044206\n",
      "MAE_V_predicted: 4.963334\n",
      "SQRT_MSE_V_predicted: 8.927807\n",
      "MEAN_BIAS_V_predicted: 0.000071\n",
      "\n",
      "experiment_3_1_part_II (expected λ)\n",
      "MAE_V_expected: 3.839313\n",
      "SQRT_MSE_V_expected: 7.056411\n",
      "MEAN_BIAS_V_expected: 0.000068\n",
      "\n",
      "experiment_3_1_part_III (λ bias comparision)\n",
      "MEAN_BIAS_lambdas_pred: 0.027761\n",
      "MEAN_BIAS_lambdas_expected: 0.000452\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE(V)</th>\n",
       "      <th>SQRT_MSE(V)</th>\n",
       "      <th>MEAN_BIAS(V)</th>\n",
       "      <th>MEAN_BIAS(λ)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Expected</th>\n",
       "      <td>3.839313</td>\n",
       "      <td>7.056411</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediced</th>\n",
       "      <td>4.963334</td>\n",
       "      <td>8.927807</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.027761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            MAE(V)  SQRT_MSE(V)  MEAN_BIAS(V)  MEAN_BIAS(λ)\n",
       "Expected  3.839313     7.056411      0.000068      0.000452\n",
       "Prediced  4.963334     8.927807      0.000071      0.027761"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_poisson_data(N, M, min_lambda=0.5, max_lambda=1.5):\n",
    "    \n",
    "    # define λ generator for 0.5 <= λ <= 1.5\n",
    "    lambda_gen = lambda: next_lambda(min_lambda=min_lambda, max_lambda=max_lambda)\n",
    "\n",
    "    raw, H, lambdas = generate_data(N=N, \n",
    "                                    M=M, \n",
    "                                    nextConfig=lambda_gen,\n",
    "                                    sample=sample_poisson, \n",
    "                                    density=False, \n",
    "                                    dense_histogram=True, \n",
    "                                    apply_log_scale=False)\n",
    "    return H, lambdas\n",
    "\n",
    "def compute_V(H, M, lambdas):\n",
    "    \"\"\"Compute values of H parameterized by lambdas and (0 <= k < M) using poisson.pmf\"\"\"\n",
    "    i,j = np.ix_(np.arange(H.shape[0]), np.arange(H.shape[1]))\n",
    "    V = H - M * poisson.pmf(k=j, mu=lambdas[i])\n",
    "    return V\n",
    "\n",
    "def calc_expected_lambdas(H, M):\n",
    "    \"\"\" return expected lambda at each row of H \"\"\"\n",
    "    k = np.ix_(np.arange(H.shape[1]))\n",
    "    return np.sum(k*H/M, axis=1)\n",
    "\n",
    "def experiment_3_1():\n",
    "\n",
    "    # for reporoducable results\n",
    "    reset_random_state(17)\n",
    "\n",
    "    # generate data (histogram and lambdas)\n",
    "    N=10000\n",
    "#lilo:     M=256\n",
    "    M=1024\n",
    "    min_lambda=0.5\n",
    "    max_lambda=1.5\n",
    "    print(f'generating data (M={M}, N={N}) ... ', end='')\n",
    "    H, lambdas = generate_poisson_data(N, M, min_lambda=min_lambda, max_lambda=max_lambda)\n",
    "    H_train, H_test, lambdas_train, lambdas_test = train_test_split(H, lambdas, test_size=0.25, \n",
    "                                                                    random_state=RANDOM_STATE)\n",
    "    print(f'histogram shape: {H_train.shape}')\n",
    "\n",
    "    ##################################################\n",
    "    # PART-I (prediced λ)\n",
    "    #\n",
    "    #   Let V = (H[k] - M * Poisson(prediced_λ,k))\n",
    "    #   Compute MAE(V), MSE(V), MEAN_BIAS(V)\n",
    "    ##################################################\n",
    "    print()\n",
    "    print(f'experiment_3_1_part_I (prediced λ)')\n",
    "\n",
    "    # fit model to train data\n",
    "    print(f'fitting dnn model ... ', end='')\n",
    "    start_time = time.time()\n",
    "    dnn_model, history = dnn_fit(X_train=H_train, y_train=lambdas_train)\n",
    "    train_time = round(time.time() - start_time)\n",
    "    print(f'duration: {round(train_time)} sec.')\n",
    "\n",
    "    # predict lambdas on test data\n",
    "    print(f'predicting lambdas ... ', end='')\n",
    "    lambdas_pred, sqrt_mse = dnn_predict(dnn_model, H_test, lambdas_test)\n",
    "    print(f'sqrt_mse(λ): {sqrt_mse:.6f}')\n",
    "    \n",
    "    # compute V(prediced_λ): V[i,j] = H_test[i,j] - M * Poisson(prediced_λ[i], j)\n",
    "    V_prediced = compute_V(H=H_test, M=M, lambdas=lambdas_pred)\n",
    "    \n",
    "    # MAE(V)\n",
    "    MAE_V_predicted = np.mean(np.abs(V_prediced))\n",
    "    print(f'MAE_V_predicted: {MAE_V_predicted:.6f}')\n",
    "    \n",
    "    # SQRT_MSE(V)\n",
    "    SQRT_MSE_V_predicted = np.sqrt(np.mean(np.square(V_prediced)))\n",
    "    print(f'SQRT_MSE_V_predicted: {SQRT_MSE_V_predicted:.6f}')\n",
    "    \n",
    "    # MEAN_BIAS(V)\n",
    "    MEAN_BIAS_V_predicted = np.mean(V_prediced)\n",
    "    print(f'MEAN_BIAS_V_predicted: {MEAN_BIAS_V_predicted:.6f}')\n",
    "\n",
    "    ##################################################\n",
    "    # PART-II (expected λ)\n",
    "    #\n",
    "    #   Let V = (H[k] - M * Poisson(expected_λ,k))\n",
    "    #   Compute MAE(V), MSE(V), MEAN_BIAS(V)\n",
    "    ##################################################\n",
    "    print()\n",
    "    print(f'experiment_3_1_part_II (expected λ)')\n",
    "\n",
    "    lambdas_expected = calc_expected_lambdas(H_test, M)\n",
    "    \n",
    "    # compute V(expected_λ): V[i,j] = H_test[i,j] - M * Poisson(λ[i], j)\n",
    "    V_expected = compute_V(H=H_test, M=M, lambdas=lambdas_expected)\n",
    "    \n",
    "    # MAE(V)\n",
    "    MAE_V_expected = np.mean(np.abs(V_expected))\n",
    "    print(f'MAE_V_expected: {MAE_V_expected:.6f}')\n",
    "    \n",
    "    # SQRT_MSE(V)\n",
    "    SQRT_MSE_V_expected = np.sqrt(np.mean(np.square(V_expected)))\n",
    "    print(f'SQRT_MSE_V_expected: {SQRT_MSE_V_expected:.6f}')\n",
    "    \n",
    "    # MEAN_BIAS(V)\n",
    "    MEAN_BIAS_V_expected = np.mean(V_expected)\n",
    "    print(f'MEAN_BIAS_V_expected: {MEAN_BIAS_V_expected:.6f}')\n",
    "\n",
    "    ##################################################\n",
    "    # PART-III (λ bias comparision)\n",
    "    #\n",
    "    #   Compare bias of predicted_λ vs expected_λ\n",
    "    ##################################################\n",
    "    print()\n",
    "    print(f'experiment_3_1_part_III (λ bias comparision)')\n",
    "    MEAN_BIAS_lambdas_pred = np.mean(lambdas_pred - lambdas_test)\n",
    "    print(f'MEAN_BIAS_lambdas_pred: {MEAN_BIAS_lambdas_pred:.6f}')\n",
    "    MEAN_BIAS_lambdas_expected = np.mean(lambdas_expected - lambdas_test)\n",
    "    print(f'MEAN_BIAS_lambdas_expected: {MEAN_BIAS_lambdas_expected:.6f}')\n",
    " \n",
    "    df = pd.DataFrame({\n",
    "        'MAE(V)': [MAE_V_expected, MAE_V_predicted],\n",
    "        'SQRT_MSE(V)': [SQRT_MSE_V_expected, SQRT_MSE_V_predicted],\n",
    "        'MEAN_BIAS(V)': [MEAN_BIAS_V_expected, MEAN_BIAS_V_predicted],\n",
    "        'MEAN_BIAS(λ)': [MEAN_BIAS_lambdas_expected, MEAN_BIAS_lambdas_pred],\n",
    "    }, index=['Expected', 'Prediced'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = experiment_3_1()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5b8bee",
   "metadata": {},
   "source": [
    "generating data (M=256, N=10000) ... histogram shape: (7500, 11)\n",
    "\n",
    "experiment_3_1_part_I (prediced λ)\n",
    "fitting dnn model ... duration: 23 sec.\n",
    "predicting lambdas ... sqrt_mse(λ): 0.060201\n",
    "MAE_V_predicted: 1.782004\n",
    "SQRT_MSE_V_predicted: 3.399430\n",
    "MEAN_BIAS_V_predicted: 0.000002\n",
    "\n",
    "experiment_3_1_part_II (expected λ)\n",
    "MAE_V_expected: 1.754229\n",
    "SQRT_MSE_V_expected: 3.370083\n",
    "MEAN_BIAS_V_expected: 0.000002\n",
    "\n",
    "experiment_3_1_part_III (λ bias comparision)\n",
    "MEAN_BIAS_lambdas_pred: 0.005243\n",
    "MEAN_BIAS_lambdas_expected: 0.000082\n",
    "MAE(V)\tSQRT_MSE(V)\tMEAN_BIAS(V)\tMEAN_BIAS(λ)\n",
    "Expected\t1.754229\t3.370083\t0.000002\t0.000082\n",
    "Prediced\t1.782004\t3.399430\t0.000002\t0.005243"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a453ae",
   "metadata": {},
   "source": [
    "## Experiment 3.2: Can we help learning of Poisson, by teaching the underlying mathematics.\n",
    "\n",
    "Learning the computed λ, by using expectation is **extremely easy** for a neural network. \n",
    "Based on #7, we hope that the DNN does better than this. So force it to do better, we give it the computed λ as input, and only ask it to learn the difference between the *real* λ (as used to synthesize the data) and the *estimator* λ. \n",
    "\n",
    "Our question is: _can we help the neural network to learn the data if we give it mathematical hints on it?_\n",
    "\n",
    "To do so, define ζ to be the estimator λ, as computed by the expectation; \n",
    "\n",
    "> $ζ = Σ_{i=0}^{K} \\frac{k * H[k]}{M}$\n",
    "\n",
    "Define a new histogram Z, computed from H, using ζ .  The new histogram will show the difference between the expected value and the real value,  i.e, run the following loop for k=0, ... , K\n",
    "\n",
    "> $Z[k] = H[k] - M * Poisson(ζ,k)$\n",
    "\n",
    "Now apply DNN. The new data includes all the data the previous DNN achieved, but in a slightly more convenient way. Hopefully, the results are better.\n",
    "\n",
    "Design and implement and experiment to give a conclusive answer to this question. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d491e65",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ou",
   "language": "python",
   "name": "ou"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
