{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f29c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "%run lib.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635cf32d",
   "metadata": {},
   "source": [
    "# Build the 2D universal estimator\n",
    "Input: two (one) dimensional function $f$ that gives the $PMF$ of a univariate distribution.\n",
    "\n",
    "> $x = f(d_1, d_2)$\n",
    "\n",
    "In Python, this comes as a simple function from $Real*Real$ to $Real[0,1]$, case in point: log-normal function.\n",
    "\n",
    "``` python\n",
    "\n",
    "def universal(f, data):\n",
    "    def g(d1, d2):\n",
    "        \"\"\" g is only defined in the cube (-pi/2, pi/2)^2 \"\"\"\n",
    "        return f(tan(d1), tan(d2))\n",
    "\n",
    "    # universal(g) { // Learn d1 and d2, of g, from the data.\n",
    "    # -1. Set U = cube (-pi/2, pi2/2)^2\n",
    "    #  0. Pick the number of sample points; should not be too large...  256 maybe.\n",
    "    #  1. Generate a dense coverage of the cube.\n",
    "    #  2. Generate the data for each point in the sample of the parameter space.\n",
    "    #  3. Apply DNN to find out d1 and d2, for the input data, this may be the final result\n",
    "    #  4. Set the cube to a cube of half the volume.\n",
    "    #  5. forget all that you learned.\n",
    "    #  6. Repeat from step 1, if the volume of the cube is greater than 1/128 of the original cube.\n",
    "    # return the estimate found in the last step 3 above.\n",
    "               \n",
    "```\n",
    "\n",
    "Algorithm:\n",
    "\n",
    "1. Transform the parameter space to unit cube of dimension n=1,2, e.g., (1+ arctan(t))/2, sigmoid.\n",
    "2. Learn the Sigmoid(t1), Sigmoid(t2) (optional: learn t1,t2, not their sigmoid) using the usual statistical method of generating synthetic data.\n",
    "3. Compute the variance of the error of learning, it is typically a function of t1, t2, e.g., the error is not the same everywhere.\n",
    "4. Compute the fisher information: Log, Derivate, Square (analytically), integrate (numerically) over x, ranging over all reals.\n",
    "5. Multiply by n (the number of sample points).\n",
    "6. Compute the inverse.\n",
    "7. Compare to the actual error from (3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ou",
   "language": "python",
   "name": "ou"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
