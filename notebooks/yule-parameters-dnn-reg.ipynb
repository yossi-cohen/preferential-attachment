{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install scipy\n",
    "# !pip install pandas\n",
    "# !pip install matplotlib\n",
    "# !pip install sklearn\n",
    "# !pip install keras\n",
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def read_csvs(csv_files, shuffle_samples=True, verbose=True):\n",
    "    '''Read one or more csv files into a single DataFrame'''\n",
    "    df = pd.DataFrame()\n",
    "    for csv in csv_files:\n",
    "        if verbose:\n",
    "            print('loading:', csv)\n",
    "        df.append(pd.read_csv(csv))\n",
    "    \n",
    "    if shuffle_samples:\n",
    "        df = shuffle(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.metrics import mean_squared_error\n",
    "\n",
    "def create_model(n_features, \n",
    "                 layers, \n",
    "                 activation='relu', \n",
    "                 init='he_uniform', \n",
    "                 batch_normalization=False, \n",
    "                 dropout=0, \n",
    "                 optimizer='adam', \n",
    "                 optimizer_lr=0.01, \n",
    "                 k_reg=False, \n",
    "                 k_reg_lr=0.001, \n",
    "                 a_reg=False, \n",
    "                 a_reg_lr=0.001, \n",
    "                 metrics=['mse']):\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    # ============\n",
    "    # input-layer\n",
    "    # ============\n",
    "    model.add(Dense(units=layers[0], \n",
    "                      input_dim=n_features, \n",
    "                      kernel_initializer=init, \n",
    "                      activation=activation))\n",
    "                      # kernel_regularizer=l2(k_reg_lr) if k_reg else None, \n",
    "                      # activity_regularizer=l2(a_reg_lr) if a_reg else None)\n",
    "    \n",
    "    \n",
    "    if batch_normalization:\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "    if dropout > 0:\n",
    "        model.add(Dropout())\n",
    "\n",
    "    # ==============\n",
    "    # hidden-layers\n",
    "    # ==============\n",
    "    for units in layers[1:]:\n",
    "        model.add(Dense(units=units, \n",
    "                        kernel_initializer=init, \n",
    "                        kernel_regularizer=l2(k_reg_lr) if k_reg else None, \n",
    "                        activity_regularizer=l2(a_reg_lr) if a_reg else None))\n",
    "\n",
    "    if batch_normalization:\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Activation(activation))\n",
    "    \n",
    "    if dropout > 0:\n",
    "        model.add(Dropout())\n",
    "\n",
    "    # =============\n",
    "    # output-layer\n",
    "    # =============\n",
    "    model.add(Dense(units=1, kernel_initializer=init))\n",
    "                  # kernel_regularizer=l2(k_reg_lr) if k_reg else None, \n",
    "                  # activity_regularizer=l2(a_reg_lr) if a_reg else None)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import pickle\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# fix random seed for reproducability\n",
    "def fix_random(seed):\n",
    "    os.environ['PYTONHASHSEED'] = '0'\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "fix_random(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 5.48 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "MODEL_PREFIX = 'yulesimon'\n",
    "\n",
    "def run(X_train, y_train):\n",
    "    model = create_model(X_train.shape[1], \n",
    "                         layers=[64, 64, 64], \n",
    "                         activation='relu', \n",
    "                         init='he_uniform', \n",
    "                         batch_normalization=False, \n",
    "                         dropout=0.15, \n",
    "                         optimizer='adam', \n",
    "                         optimizer_lr=0.0001, \n",
    "                         k_reg=False, \n",
    "                         k_reg_lr=1e-5, \n",
    "                         a_reg=False, \n",
    "                         a_reg_lr=1e-6, \n",
    "                         metrics=['mse'])\n",
    "    \n",
    "    # split train/validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1)\n",
    "    \n",
    "    # early-stopping\n",
    "    es_patience = 100\n",
    "    es_ = EarlyStopping(monitor='val_loss', \n",
    "                        patience=es_patience, \n",
    "                        mode='min', \n",
    "                        restore_best_weights=True, \n",
    "                        verbose=1)\n",
    "    \n",
    "    # model checkpoint\n",
    "    date_str = datetimet.now().strftime('%d-%m-%Y_%H-%M-%S')\n",
    "    model_path = 'models/{}_{}.h5'.format(MODEL_PREFIX, date_str)\n",
    "    print('model path:', model_path)\n",
    "    \n",
    "    cp = ModelCheckpoint(filepath=model_path, monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "    \n",
    "    # reduce learning-rate on plateau\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=min(30, int(es_patience/2)))\n",
    "    \n",
    "    # fit model\n",
    "    history = model.fit(X_train, \n",
    "                        y_train, \n",
    "                        validation_data=(X_val, y_val), \n",
    "                        ephochs=10000, \n",
    "                        batch_size=BATCH_SIZE, \n",
    "                        shuffle=False, callbacks=[es, reduce_lr, cp], \n",
    "                        verbose=1)\n",
    "    \n",
    "    history_unique_name = 'models/{}_{}.history'.format(MODEL_PREFIX, date_str)\n",
    "    with open(history_unique_name, 'wb') as f:\n",
    "        pickle.dump(history, f)\n",
    "    \n",
    "    # load best weights from last checkpoint\n",
    "    model = keras.models.load_model(model_path)\n",
    "        \n",
    "    return model, history\n",
    "\n",
    "if False:\n",
    "    run(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ou",
   "language": "python",
   "name": "ou"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
