{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"poisson-exp-2.ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"023fb420"},"source":["# Experiment 2\n","Given an actual (true) poisson sample, use regression to estimate $\\lambda$ for this sample.\n","- Measure error relative to actual data\n","\n","## Example\n","WW II London bombings  \n","see: [https://towardsdatascience.com/poisson-distribution-from-horse-kick-history-data-to-modern-analytic-5eb49e60fb5f]\n","\n","![WW-II-London-bombings.png](attachment:WW-II-London-bombings.png)\n"],"id":"023fb420"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YgF3G8Ov_RPy","executionInfo":{"status":"ok","timestamp":1626972233940,"user_tz":-180,"elapsed":393,"user":{"displayName":"Yossi Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiujkWmAoNeSugTeNEBCFVhsVizxpys4rfiqkLl=s64","userId":"01044449452533476970"}},"outputId":"ddcee70c-91ef-4d32-ce1b-9aee638d8ad7"},"source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n","%cd '/content/drive/MyDrive/Colab Notebooks/preferential-attachment/notebooks'"],"id":"YgF3G8Ov_RPy","execution_count":1,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/preferential-attachment/notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6T2HxM-3_-1I","executionInfo":{"status":"ok","timestamp":1626972234362,"user_tz":-180,"elapsed":17,"user":{"displayName":"Yossi Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiujkWmAoNeSugTeNEBCFVhsVizxpys4rfiqkLl=s64","userId":"01044449452533476970"}}},"source":["# !git config --global user.email yossi.cohen@live.com”\n","# !git config --global user.name “Yossi Cohen”\n","# !git commit -am \"ref\"\n","# !git push"],"id":"6T2HxM-3_-1I","execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fe02c230"},"source":["## Imports"],"id":"fe02c230"},{"cell_type":"code","metadata":{"id":"e35762d2","executionInfo":{"status":"ok","timestamp":1626972237183,"user_tz":-180,"elapsed":2835,"user":{"displayName":"Yossi Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiujkWmAoNeSugTeNEBCFVhsVizxpys4rfiqkLl=s64","userId":"01044449452533476970"}}},"source":["# import library\n","%run lib.ipynb"],"id":"e35762d2","execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c1969402"},"source":["## Experiment 2.1 - measure statistical error\n","\n","1. Generate data ($N$ rows, $M$ poisson samples in a row, each row with a random $\\lambda$ in the range $0.1 \\le \\lambda \\le 10$)\n","2. $sample_i$ generated sinthetically with a specific $\\lambda_i$ contains M samples ordered in a histogram $H_i$ with $m$ bins.\n","    - Fix $i$\n","    - for each $k \\in [\\;0\\;..\\;m\\;]$\n","        - $collect(poisson.pmf(k, \\lambda) - H_{ik})$ -> statistical error in $sample_i$\n","    - calculate MSE(collection)\n","    - calculate MAE(collection)"],"id":"c1969402"},{"cell_type":"code","metadata":{"id":"9630c832","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626972237963,"user_tz":-180,"elapsed":794,"user":{"displayName":"Yossi Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiujkWmAoNeSugTeNEBCFVhsVizxpys4rfiqkLl=s64","userId":"01044449452533476970"}},"outputId":"b96a743a-c5d4-4de8-d903-bcd565b9b0c0"},"source":["def experiment_2_1():\n","\n","    # 1. generate data\n","\n","    M = 16  # num-samples\n","    print(f'generating {M} poisson samples ... ')\n","    raw, H, lambdas = generate_data(N=1, \n","                                    M=M, \n","                                    nextConfig=next_lambda, \n","                                    sample=sample_poisson, \n","                                    density=False, \n","                                    dense_histogram=False)\n","\n","    # 2. measure poisson statistical error\n","\n","    with np.printoptions(precision=5, suppress=True):\n","\n","        i = 0\n","        print(f'Poisson statistical error for sample(i = {i})')\n","\n","        print()\n","        print(f'λ[i] : {lambdas[i]:.6f}')\n","\n","        print()\n","        print(f'Raw samples (len={len(raw[0])}):')\n","        print(raw[i])\n","\n","        # poisson generated (actual) values\n","        print()\n","        m = len(H[i])\n","        print(f'Histogram (num_bins={m}):')\n","        print(H[i])\n","\n","        print()\n","        H_i_normalized = H[i] / np.sum(H[i])\n","        print(f'Normalized histogram (sum={np.sum(H_i_normalized)}):')\n","        print(H_i_normalized)\n","\n","        # poisson calculated values\n","        print()\n","        print(f'Calculated values - pmf(k,λ)')\n","        poisson_pmf = np.array( [ poisson.pmf(k=j, mu=lambdas[i]) for j in range(m) ] )\n","        print(poisson_pmf)\n","\n","        # MSE\n","        print()\n","        MSE = mean_squared_error(poisson_pmf, H_i_normalized)\n","        print(f'MSE: {MSE:.6f}    sqrt(MSE): {np.sqrt(MSE):.6f}')\n","\n","        # MAE\n","        MAE = mean_absolute_error(poisson_pmf, H_i_normalized)\n","        print(f'MAE: {MAE:.6f}')\n","\n","experiment_2_1()"],"id":"9630c832","execution_count":4,"outputs":[{"output_type":"stream","text":["generating 16 poisson samples ... \n","Poisson statistical error for sample(i = 0)\n","\n","λ[i] : 3.017184\n","\n","Raw samples (len=16):\n","[2 4 2 2 4 4 1 1 2 1 3 3 5 3 3 2]\n","\n","Histogram (num_bins=16):\n","[0 3 5 4 3 1 0 0 0 0 0 0 0 0 0 0]\n","\n","Normalized histogram (sum=1.0):\n","[0.     0.1875 0.3125 0.25   0.1875 0.0625 0.     0.     0.     0.\n"," 0.     0.     0.     0.     0.     0.    ]\n","\n","Calculated values - pmf(k,λ)\n","[0.04894 0.14766 0.22275 0.22403 0.16899 0.10197 0.05128 0.0221  0.00834\n"," 0.00279 0.00084 0.00023 0.00006 0.00001 0.      0.     ]\n","\n","MSE: 0.001113    sqrt(MSE): 0.033362\n","MAE: 0.021759\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"c4337530"},"source":["## Experiment 2.2 - measure the error compared to actual data\n","\n","1. Fit a DNN regression *model* for $\\lambda \\in [\\lambda_{min}\\;...\\;\\lambda_{max}]$.\n","2. Given an actual poisson sample ordered in a histogram $H$ (without indices):  \n","   Feed $H$ to the *model* to predict $\\lambda$\n","3. Measure the avg. error of the prediction relative to the actual values:  \n","   $MAE = avg\\;(\\;|\\;P_j(\\lambda)\\;-\\;H(\\lambda)\\;|\\;)$"],"id":"c4337530"},{"cell_type":"code","metadata":{"id":"578bd488","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626972384346,"user_tz":-180,"elapsed":146391,"user":{"displayName":"Yossi Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiujkWmAoNeSugTeNEBCFVhsVizxpys4rfiqkLl=s64","userId":"01044449452533476970"}},"outputId":"d7290c20-4f0e-4816-8d3d-6f2ab65953c4"},"source":["def experiment_2_2(N, M, test_lambda=0.92):\n","    \n","    # for reporoducable results\n","    reset_random_state(17)\n","    \n","    # constants\n","    density=False\n","    apply_log_scale=False\n","    \n","    # generate training data (histogram and lambdas)\n","    print(f'generating data (M={M}) ... ', end='')\n","    raw, H, lambdas = generate_data(N=N, \n","                                    M=M, \n","                                    nextConfig=next_lambda, \n","                                    sample=sample_poisson, \n","                                    density=density, \n","                                    dense_histogram=True, \n","                                    apply_log_scale=apply_log_scale)\n","    # fit model\n","    X_train, X_test, y_train, y_test = train_test_split(H, lambdas, test_size=0.25, random_state=RANDOM_STATE)\n","    print(f'X_train.shape: {X_train.shape}')\n","    print(f'fitting dnn model ... ', end='')\n","    start_time = time.time()\n","    dnn_model, history, y_pred, sqrt_mse = dnn_trial(X_train, y_train, X_test, y_test)\n","    train_time = round(time.time() - start_time)\n","    print(f'sqrt-mse: {sqrt_mse:.4f}, train-time: {round(train_time)} sec.')\n","\n","    # generate test histogram\n","    print(f'test_lambda: {test_lambda:.6f}')\n","    test_samples = sample_poisson(mu=test_lambda, size=M) #lilo: size=10\n","    bins = X_train.shape[1] # same input size as training data\n","    test_histogram = np.apply_along_axis(\n","        lambda a: np.histogram(a, bins=bins, range=(0, bins), density=density)[0], \n","        0, \n","        test_samples)\n","    \n","    # apply log-scale also on test_histogram\n","    if apply_log_scale:\n","        test_histogram = log_scale(test_histogram)\n","    \n","    test_pmf = test_histogram / np.sum(test_histogram)\n","    \n","    # predict lambda for the actual histogram\n","    test_input = np.reshape(test_histogram, (1,-1))\n","    predicted_lambda = dnn_model.predict(test_input).flatten()[0]\n","    print(f'predicted_lambda: {predicted_lambda:.6f}')\n","    predicted_pmf = np.array([poisson.pmf(k=i, mu=predicted_lambda) for i in range(bins)])\n","\n","    # MSE\n","    print()\n","    MSE = mean_squared_error(test_pmf, predicted_pmf)\n","    print(f'MSE: {MSE:.6f}    sqrt(MSE): {np.sqrt(MSE):.6f}')\n","\n","    # MAE\n","    MAE = mean_absolute_error(test_pmf, predicted_pmf)\n","    print(f'MAE: {MAE:.6f}')\n","\n","# experiment_2_2(N=10000, M=64, test_lambda=0.92)    # predicted_lambda: 0.854302\n","\n","# experiment_2_2(N=10000, M=256, test_lambda=0.33)   # predicted_lambda: 0.339323\n","experiment_2_2(N=10000, M=256, test_lambda=0.92)   # predicted_lambda: 0.922885\n","# experiment_2_2(N=10000, M=256, test_lambda=2.00)   # predicted_lambda: 2.000334\n","# experiment_2_2(N=10000, M=256, test_lambda=1.56)   # predicted_lambda: 1.568572\n","# experiment_2_2(N=10000, M=256, test_lambda=3.52)   # predicted_lambda: 3.665080\n","# experiment_2_2(N=10000, M=256, test_lambda=9.89)   # predicted_lambda: 9.967596\n","\n","# experiment_2_2(N=10000, M=512, test_lambda=0.92)   # predicted_lambda: 0.930573\n","# experiment_2_2(N=10000, M=8192, test_lambda=0.92)  # predicted_lambda: 1.017836\n","# experiment_2_2(N=10000, M=16384, test_lambda=0.92) # predicted_lambda: 0.750495\n"],"id":"578bd488","execution_count":5,"outputs":[{"output_type":"stream","text":["generating data (M=256) ... X_train.shape: (7500, 26)\n","fitting dnn model ... sqrt-mse: 0.1497, train-time: 144 sec.\n","test_lambda: 0.920000\n","predicted_lambda: 0.956448\n","\n","MSE: 0.000103    sqrt(MSE): 0.010153\n","MAE: 0.003564\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"422fb42a"},"source":["## Experiment 2.3\n","Predict $\\lambda$ for actual data using a specific regression model (overfit).\n","- auto-encoder single neuron at the middle?\n","- just like by-hand?"],"id":"422fb42a"},{"cell_type":"code","metadata":{"code_folding":[],"id":"5d491e65","executionInfo":{"status":"ok","timestamp":1626972384347,"user_tz":-180,"elapsed":21,"user":{"displayName":"Yossi Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiujkWmAoNeSugTeNEBCFVhsVizxpys4rfiqkLl=s64","userId":"01044449452533476970"}}},"source":["# TODO"],"id":"5d491e65","execution_count":6,"outputs":[]}]}