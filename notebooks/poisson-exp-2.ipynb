{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "023fb420",
   "metadata": {},
   "source": [
    "# Experiment 2\n",
    "Given an actual (true) poisson sample, use regression to estimate $\\lambda$ for this sample.\n",
    "- Measure error relative to actual data\n",
    "- see: [https://towardsdatascience.com/poisson-distribution-from-horse-kick-history-data-to-modern-analytic-5eb49e60fb5f]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe02c230",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e35762d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "%run lib.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1969402",
   "metadata": {},
   "source": [
    "## Experiment 2.1 - measure statistical error\n",
    "\n",
    "1. Generate data ($N$ rows, $M$ poisson samples in a row, each row with a random $\\lambda$ in the range $0.1 \\le \\lambda \\le 10$)\n",
    "2. $sample_i$ generated sinthetically with a specific $\\lambda_i$ contains M samples ordered in a histogram $H_i$ with $m$ bins.\n",
    "    - Fix $i$\n",
    "    - for each $k \\in [\\;0\\;..\\;m\\;]$\n",
    "        - $collect(poisson.pmf(k, \\lambda) - H_{ik})$ -> statistical error in $sample_i$\n",
    "    - calculate MSE(collection)\n",
    "    - calculate MAE(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9630c832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating 16 poisson samples ... \n",
      "Poisson statistical error for sample(i = 0)\n",
      "\n",
      "位[i] : 3.017184\n",
      "\n",
      "Raw samples (len=16):\n",
      "[2 4 2 2 4 4 1 1 2 1 3 3 5 3 3 2]\n",
      "\n",
      "Histogram (num_bins=16):\n",
      "[0 3 5 4 3 1 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Normalized histogram (sum=1.0):\n",
      "[0.     0.1875 0.3125 0.25   0.1875 0.0625 0.     0.     0.     0.\n",
      " 0.     0.     0.     0.     0.     0.    ]\n",
      "\n",
      "Calculated values - pmf(k,位)\n",
      "[0.04894 0.14766 0.22275 0.22403 0.16899 0.10197 0.05128 0.0221  0.00834\n",
      " 0.00279 0.00084 0.00023 0.00006 0.00001 0.      0.     ]\n",
      "\n",
      "MSE: 0.001113    sqrt(MSE): 0.033362\n",
      "MAE: 0.021759\n"
     ]
    }
   ],
   "source": [
    "def experiment_2_1():\n",
    "\n",
    "    # 1. generate data\n",
    "\n",
    "    M = 16  # num-samples\n",
    "    print(f'generating {M} poisson samples ... ')\n",
    "    raw, H, lambdas = generate_data(N=1, \n",
    "                                    M=M, \n",
    "                                    nextConfig=next_lambda, \n",
    "                                    sample=sample_poisson, \n",
    "                                    density=False, \n",
    "                                    dense_histogram=False)\n",
    "\n",
    "    # 2. measure poisson statistical error\n",
    "\n",
    "    with np.printoptions(precision=5, suppress=True):\n",
    "\n",
    "        i = 0\n",
    "        print(f'Poisson statistical error for sample(i = {i})')\n",
    "\n",
    "        print()\n",
    "        print(f'位[i] : {lambdas[i]:.6f}')\n",
    "\n",
    "        print()\n",
    "        print(f'Raw samples (len={len(raw[0])}):')\n",
    "        print(raw[i])\n",
    "\n",
    "        # poisson generated (actual) values\n",
    "        print()\n",
    "        m = len(H[i])\n",
    "        print(f'Histogram (num_bins={m}):')\n",
    "        print(H[i])\n",
    "\n",
    "        print()\n",
    "        H_i_normalized = H[i] / np.sum(H[i])\n",
    "        print(f'Normalized histogram (sum={np.sum(H_i_normalized)}):')\n",
    "        print(H_i_normalized)\n",
    "\n",
    "        # poisson calculated values\n",
    "        print()\n",
    "        print(f'Calculated values - pmf(k,位)')\n",
    "        poisson_pmf = np.array( [ poisson.pmf(k=j, mu=lambdas[i]) for j in range(m) ] )\n",
    "        print(poisson_pmf)\n",
    "\n",
    "        # MSE\n",
    "        print()\n",
    "        MSE = mean_squared_error(poisson_pmf, H_i_normalized)\n",
    "        print(f'MSE: {MSE:.6f}    sqrt(MSE): {np.sqrt(MSE):.6f}')\n",
    "\n",
    "        # MAE\n",
    "        MAE = mean_absolute_error(poisson_pmf, H_i_normalized)\n",
    "        print(f'MAE: {MAE:.6f}')\n",
    "\n",
    "experiment_2_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4337530",
   "metadata": {},
   "source": [
    "## Experiment 2.2 - measure the error compared to actual data\n",
    "\n",
    "1. Fit a DNN regression *model* for $\\lambda \\in [\\lambda_{min}\\;...\\;\\lambda_{max}]$.\n",
    "2. Given an actual poisson sample ordered in a histogram $H$ (without indices):  \n",
    "   Feed $H$ to the *model* to predict $\\lambda$\n",
    "3. Measure the avg. error of the prediction relative to the actual values:  \n",
    "   $MAE = avg\\;(\\;|\\;P_j(\\lambda)\\;-\\;H(\\lambda)\\;|\\;)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "578bd488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_lambda: 0.920000\n",
      "generating data (M=256, N=10000) ... histogram shape: (7500, 12)\n",
      "fitting dnn model ... sqrt-mse: 0.0632, train-time: 42 sec.\n",
      "M: 256, predicted_lambda: 1.032317, MSE: 0.000099, sqrt(MSE): 0.009951, MAE: 0.005294\n"
     ]
    }
   ],
   "source": [
    "def experiment_2_2(N, M, test_lambda=0.92, lambda_gen=None):\n",
    "    \n",
    "    # for reporoducable results\n",
    "    reset_random_state(17)\n",
    "    \n",
    "    if None == lambda_gen:\n",
    "        lambda_gen = next_lambda\n",
    "        \n",
    "    # constants\n",
    "    density=False\n",
    "    apply_log_scale=False\n",
    "\n",
    "    print(f'test_lambda: {test_lambda:.6f}')\n",
    "    \n",
    "    # generate training data (histogram and lambdas)\n",
    "    print(f'generating data (M={M}, N={N}) ... ', end='')\n",
    "    raw, H, lambdas = generate_data(N=N, \n",
    "                                    M=M, \n",
    "                                    nextConfig=lambda_gen,\n",
    "                                    sample=sample_poisson, \n",
    "                                    density=density, \n",
    "                                    dense_histogram=True, \n",
    "                                    apply_log_scale=apply_log_scale)\n",
    "    # fit model\n",
    "    H_train, H_test, lambdas_train, lambdas_test = train_test_split(H, lambdas, test_size=0.25, \n",
    "                                                                    random_state=RANDOM_STATE)\n",
    "    print(f'histogram shape: {H_train.shape}')\n",
    "    print(f'fitting dnn model ... ', end='')\n",
    "    start_time = time.time()\n",
    "    dnn_model, history, lambdas_pred, sqrt_mse = dnn_trial(H_train, lambdas_train, H_test, lambdas_test)\n",
    "    train_time = round(time.time() - start_time)\n",
    "    print(f'sqrt-mse: {sqrt_mse:.4f}, train-time: {round(train_time)} sec.')\n",
    "\n",
    "    # generate test histogram\n",
    "    test_samples = sample_poisson(mu=test_lambda, size=M)\n",
    "    bins = H_train.shape[1] # same input size as training data\n",
    "    test_histogram = np.apply_along_axis(\n",
    "        lambda a: np.histogram(a, bins=bins, range=(0, bins), density=density)[0], \n",
    "        0, \n",
    "        test_samples)\n",
    "    \n",
    "    # apply log-scale also on test_histogram\n",
    "    if apply_log_scale:\n",
    "        test_histogram = log_scale(test_histogram)\n",
    "    \n",
    "    test_pmf = test_histogram / np.sum(test_histogram)\n",
    "    \n",
    "    # predict lambda for the actual histogram\n",
    "    test_input = np.reshape(test_histogram, (1,-1))\n",
    "    predicted_lambda = dnn_model.predict(test_input).flatten()[0]\n",
    "    #print(f'predicted_lambda: {predicted_lambda:.6f}')\n",
    "    predicted_pmf = np.array([poisson.pmf(k=i, mu=predicted_lambda) for i in range(bins)])\n",
    "\n",
    "    # MSE\n",
    "    MSE = mean_squared_error(test_pmf, predicted_pmf)\n",
    "    #print(f'MSE: {MSE:.6f}    sqrt(MSE): {np.sqrt(MSE):.6f}')\n",
    "\n",
    "    # MAE\n",
    "    MAE = mean_absolute_error(test_pmf, predicted_pmf)\n",
    "    #print(f'MAE: {MAE:.6f}')\n",
    "\n",
    "    print(f'M: {M}', end=', ')\n",
    "    print(f'predicted_lambda: {predicted_lambda:.6f}', end=', ')\n",
    "    print(f'MSE: {MSE:.6f}', end=', ')\n",
    "    print(f'sqrt(MSE): {np.sqrt(MSE):.6f}', end=', ')\n",
    "    print(f'MAE: {MAE:.6f}')\n",
    "    \n",
    "lambda_gen = lambda: next_lambda(min_lambda=0.1, max_lambda=2)\n",
    "experiment_2_2(N=10000, M=256, test_lambda=0.92, lambda_gen=lambda_gen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ou",
   "language": "python",
   "name": "ou"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
