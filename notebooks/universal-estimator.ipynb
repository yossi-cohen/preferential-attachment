{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fbfe3f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Universal estimator\n",
    "\n",
    "Let $f(x|d_1,...,d_n)$ be a function, that for any fixed values of the parameters $d_i$, reduces to a PDF of x; $f$ thus is a family of functions, e.g., *log normal*.\n",
    "\n",
    "$estimator(f, sample)$ is a function which learns the parameters $d_i$ of $f$ from a single input *sample* ($m$ observations drawn using $f$).\n",
    "\n",
    "## Method\n",
    "> 1. Generate synthetic *samples*.\n",
    "> 2. Learn a DNN model from the synthetic data.\n",
    "> 3. Predict the parameters $d_i$ on the input *sample*.\n",
    "\n",
    "## Parameter range adjustment\n",
    "The *estimator* is allowed to assume that the range of the parameter values is $(-\\frac{1}{2}, \\frac{1}{2})$.\n",
    "\n",
    "For that we use *Range Adjustment*:\n",
    "> Input:\n",
    "> 1. A funation $f(x|d_i)$ as defined above\n",
    "> 2. Bounds on the parameters $d_i$\n",
    "\n",
    "> Output:\n",
    "> - A function $g(x|t_i)$, which is the same as $f$, except that $t_i$ are in the range $(-\\frac{1}{2}, \\frac{1}{2})$, \n",
    "> and such that $t_i$ are ‚Äútypically‚Äù around 0.\n",
    "\n",
    "> Let: $h(d)$ be a mapping function from $range(d)$ to the range $(-\\frac{1}{2}, \\frac{1}{2})$, where $h$ is continuous within $range(d)$.\n",
    ">\n",
    "> $h^{-1}(t)$ is therefore a mapping function from the range $(-\\frac{1}{2}, \\frac{1}{2})$ to $range(d)$.\n",
    ">\n",
    "> Let: $g(x|t_i) = f(x|h^{-1}(t_i))$ where $h^{-1}(t_i)$ is a inverse of the *mapping* $h(d)$ of the bounds on the parameters $d_i$.\n",
    "\n",
    "We use the *range adjustment* as follows:\n",
    "> 1. Generate synthetic *samples* using $f(x|h^{-1}(t_i))$ where $t_i$ are drawn from $(-\\frac{1}{2}, \\frac{1}{2})$.\n",
    "> 2. Learn a DNN model from the synthetic data.\n",
    "> 3. Predict the parameters $d_i$ on the input *sample*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e881b07b",
   "metadata": {},
   "source": [
    "### Range adjustment using $logit(x)$\n",
    "The standard *logistic* function is defined as: $ùúé(x) = 1 / (1 + e^{-x})$ for $x ‚àà (-‚àû, ‚àû)$.\n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"images/logistic.png\" alt=\"logistic(x)\" title=\"logistic(x), x ‚àà (‚àí‚àû,‚àû)\" /></p>\n",
    "\n",
    "The *logit* is the inverse of the *logistic* function.\n",
    "\n",
    "The *logit* function is defined as: $logit(x) = ùúé^{-1}(x) = ln( x / (1-x) )$ for $x ‚àà (0,1)$.\n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"images/logit.png\" alt=\"logit\" title=\"logit(x), x ‚àà (0,1)\" /></p>\n",
    "\n",
    "We can use the *logistic* function and its *logit* inverse as follows:\n",
    "> Let: $h(d) = logit(d)$ for $d ‚àà (0,1)$\n",
    ">\n",
    "> Than $h^{-1}(t) = ùúé(t)$ for $t ‚àà (-‚àû, ‚àû)$\n",
    "\n",
    "> We define a function to return another function, i.e., an adjuster of a parameter from the range $(0, 1)$ \n",
    ">\n",
    "> to the original range $(low, high)$ that a function takes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8d84851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# from scipy.special import expit, logit\n",
    "\n",
    "def expit(x):\n",
    "    # expit(x) = 1 / (1 + e^(-x))\n",
    "    # defined in (-INF, INF)\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def logit(p):\n",
    "    # logit(p) = inv(expit) = ln(p/(1-p))\n",
    "    # defined in (0, 1)\n",
    "    if 0 == p: return -math.inf\n",
    "    if 1 == p: return math.inf\n",
    "    return math.log(p/(1-p))\n",
    "\n",
    "def adjuster_logit(low, high):\n",
    "    # adjuster is defined in (-INF, INF)\n",
    "    # low: parameter lower bound\n",
    "    # high: parameter higher bound\n",
    "    # return: a function defined in (0,1) that maps it's parameter (x) to the original range (low,high).\n",
    "\n",
    "    LOW = 0 if -math.inf == low else expit(low)\n",
    "    HIGH = 1 if math.inf == high else expit(high)\n",
    "\n",
    "    def adjust(x):\n",
    "        # adjust is defined in (0, 1)\n",
    "        if x < 0: return -math.inf\n",
    "        if x > 1: return math.inf\n",
    "        return logit(LOW + x * (HIGH - LOW))\n",
    "    \n",
    "    return adjust\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d885e1",
   "metadata": {},
   "source": [
    "### Range adjustment using $arctan(x)$\n",
    "> <img src=\"images/tan.png\" />\n",
    "> <img src=\"images/arctan.png\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3be9ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjuster_arctan(low, high):\n",
    "    # adjuster is defined in (-INF, INF)\n",
    "    # low: parameter lower bound\n",
    "    # high: parameter higher bound\n",
    "    # return: a function defined in (0,1) that maps it's parameter (x) to the original range (low,high).\n",
    "\n",
    "    LOW = -math.pi/2 if -math.inf == low else math.atan(low)\n",
    "    HIGH = math.pi/2 if math.inf == high else math.atan(high)\n",
    "\n",
    "    def adjust(x):\n",
    "        # adjust is defined in (0, 1)\n",
    "        if x < 0: return -math.inf\n",
    "        if x > 1: return math.inf\n",
    "        return math.tan(LOW + x * (HIGH - LOW))\n",
    "    \n",
    "    return adjust"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57a897e-9654-432b-914d-2f4d7b541064",
   "metadata": {},
   "source": [
    "### Test adjusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40c1d774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adjuster_logit(2,10)(0): -2.0\n",
      "adjuster_logit(2,10)(1): 10.00000000000097\n",
      "adjuster_arctan(2,10)(0): -1.9999999999999996\n",
      "adjuster_arctan(2,10)(1): 10.00000000000001\n"
     ]
    }
   ],
   "source": [
    "print(f\"adjuster_logit(2,10)(0): {adjuster_logit(low=-2, high=10)(0)}\")\n",
    "print(f\"adjuster_logit(2,10)(1): {adjuster_logit(low=-2, high=10)(1)}\")\n",
    "print(f\"adjuster_arctan(2,10)(0): {adjuster_arctan(low=-2, high=10)(0)}\")\n",
    "print(f\"adjuster_arctan(2,10)(1): {adjuster_arctan(low=-2, high=10)(1)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b2a0b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust = adjuster_logit(low=0, high=10.0)\n",
    "# adjust( np.random.uniform(0.0, 1.0, size=1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736504a8",
   "metadata": {},
   "source": [
    "# Universal estimator\n",
    "\n",
    "-  Apply 2D  range adjustment; for now, it will be independent parameters: should adjust to $(-\\frac{1}{2}, \\frac{1}{2})^2, (n=2)$.  \n",
    "   In this case: we want the range to be an n-dimensional unit cube; this makes it easier to understand subranges: e.g., 0.1-0.2.  \n",
    "   We also introduce some \"prior\" in a very convoluted way. A priori, the range is -‚àû to +‚àû and we know nothing about where the parameter is. After range adjustment, we shrink some regions by a large factor and others by a small factor. So, we favor the center of the range. We may even beat Cramer-Rao for this reason.\n",
    "\n",
    "-  Select 5 or so longtail distributions (we may need to change the families later). Do range adjustment, and it should be sensible in the sense that it is approximately centered.\n",
    "\n",
    "- Do range adjustment (orthogonal for now, i.e, independently for each original parameter).\n",
    "\n",
    "- Draw a mesh on the unit square, say with a resolution of 0.1, this gives 81 points for each mesh. Maybe 1/11 resolution? Maybe include the last and first row and column. \n",
    "\n",
    "- For each point in the mesh, run learning experiment producing:\n",
    "   - Several (say 10-100) learning experiments. without focusing for now.\n",
    "   - Compute the average error of the 10-100 experiments. MSE rules\n",
    "   - Compute the Cramer Rao bound (numerically if the analytical solution is not possible)\n",
    "   - Divide the MSE by Cramer Rao.\n",
    "  \n",
    "- Draw the 3D manifold on the mesh.\n",
    "\n",
    "### Expected results:\n",
    "\n",
    "1. Hopefully, we are at most 2 times worse than CR. \n",
    "2. Hopefully, the CR is never singular, i.e. not zero nor infinity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40cf2a9",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa550000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def generate_data(N, M, f, ranges, nbins=-1):\n",
    "    \"\"\"\n",
    "    N:      number of samples\n",
    "    M:      number of observations in each sample\n",
    "    f:      the function to generate samples\n",
    "    ranges: [dX2] array of parameter ranges (e.g. for 2 parmeters: [[0, 10], [0, math.inf]])\n",
    "    \"\"\"\n",
    "    \n",
    "    # output (generate samples)\n",
    "    samples = np.zeros((N, M), dtype=float)\n",
    "    \n",
    "    ti_low = 0.0\n",
    "    ti_high = 1.0\n",
    "    \n",
    "    # generate N parameter cubes in the range (ti_low, ti_high)\n",
    "    n_params = ranges.shape[0]\n",
    "    params = np.zeros((N, n_params), dtype=float)\n",
    "\n",
    "    param_adjusters = [adjuster_logit(low=r[0], high=r[1]) for r in ranges]\n",
    "        \n",
    "    for i in range(N):\n",
    "        for param_i in range(n_params):\n",
    "            adjuster = param_adjusters[param_i]\n",
    "            # ti is in (ti_low, ti_high)\n",
    "            ti = np.random.uniform(ti_low, ti_high, size=1)[0]\n",
    "            # di is in (di_low, di_high)\n",
    "            params[i, param_i] = adjuster(ti)\n",
    "    \n",
    "    # repeat N times: draw a sample from distribution (M observations)\n",
    "    for i in range(N):\n",
    "        samples[i, :] = f(params[i], size=M)\n",
    "    \n",
    "    # create a histogram from each sample\n",
    "    if nbins < 0:\n",
    "        nbins = int(np.max(samples))+1\n",
    "    \n",
    "    histogram_matrix = np.apply_along_axis(\n",
    "       lambda a: np.histogram(a, bins=nbins, range=(0, nbins), density=False)[0], 1, samples)\n",
    "\n",
    "    return samples, params, histogram_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61e182a",
   "metadata": {},
   "source": [
    "###  Longtail distributions for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdbad834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats import yulesimon\n",
    "from scipy.stats import powerlaw\n",
    "\n",
    "def yulesimon_sample(params, size):\n",
    "    return yulesimon.rvs(alpha=params[0], loc=params[1], size=size)\n",
    "\n",
    "def powerlaw_sample(params, size):\n",
    "    return powerlaw.rvs(a=params[0], loc=params[1], size=size)\n",
    "\n",
    "dist = {\n",
    "    'yulesimon': {\n",
    "        'sample': yulesimon_sample,\n",
    "        'ranges': np.array([[2.0, 3.0], [0.0, math.inf]])\n",
    "    },\n",
    "    'powerlaw': {\n",
    "        'sample': powerlaw_sample,\n",
    "        'ranges': np.array([[0.0, 10.0], [0.0, math.inf]])\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5033ad3",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9df3e8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.6.0\n"
     ]
    }
   ],
   "source": [
    "# import dnn library\n",
    "%run dnn.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3a5339",
   "metadata": {},
   "source": [
    "### Caching\n",
    "Use cached samples to reduced processing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6e394c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "class MeshPointsCache():\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.cached_samples = None\n",
    "\n",
    "    def key(self, ti):\n",
    "        # key = parameters joined with '|' e.g: '0.1|0.2'\n",
    "        return \"|\".join([str(t) for t in ti])\n",
    "\n",
    "    def add(self, ti, mse):\n",
    "        # add mesh point to cache\n",
    "        key = self.key(ti)\n",
    "        if not self.cached_samples:\n",
    "            self.cached_samples = {}\n",
    "        self.cached_samples[key] = mse\n",
    "        values = [key, mse]\n",
    "        with open(self.path,'a') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(values)\n",
    "\n",
    "    def load(self):\n",
    "        self.cached_samples = {}\n",
    "        if os.path.exists(self.path):\n",
    "            with open(self.path, mode='r') as f:\n",
    "                reader = csv.reader(f)\n",
    "                for row in reader:\n",
    "                    k, v = row\n",
    "                    self.cached_samples[k] = float(v)\n",
    "\n",
    "    def get_mse(self, ti):\n",
    "        if None == self.cached_samples:\n",
    "            self.load()\n",
    "        mse = self.cached_samples.get(self.key(tuple(ti)))\n",
    "        return mse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587080ee",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd601eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training mesh point - (ti: [0.1 0.1]), (di: [2.0702 0.2007])\n",
      "sample (0/81) trial (0/2) ... mse: 0.1089 (11 sec.)\n",
      "sample (0/81) trial (1/2) ... mse: 0.1792 (5 sec.)\n",
      "done sample (0/81) - (avg_mse: 0.1441)\n",
      "training mesh point - (ti: [0.1 0.2]), (di: [2.0702 0.4055])\n",
      "sample (1/81) trial (0/2) ... mse: 0.0332 (6 sec.)\n",
      "sample (1/81) trial (1/2) ... mse: 0.0650 (5 sec.)\n",
      "done sample (1/81) - (avg_mse: 0.0491)\n",
      "training mesh point - (ti: [0.1 0.3]), (di: [2.0702 0.619 ])\n",
      "sample (2/81) trial (0/2) ... mse: 0.0259 (8 sec.)\n",
      "sample (2/81) trial (1/2) ... mse: 0.0192 (9 sec.)\n",
      "done sample (2/81) - (avg_mse: 0.0225)\n",
      "training mesh point - (ti: [0.1 0.4]), (di: [2.0702 0.8473])\n",
      "sample (3/81) trial (0/2) ... mse: 0.0505 (6 sec.)\n",
      "sample (3/81) trial (1/2) ... mse: 0.1219 (7 sec.)\n",
      "done sample (3/81) - (avg_mse: 0.0862)\n",
      "training mesh point - (ti: [0.1 0.5]), (di: [2.0702 1.0986])\n",
      "sample (4/81) trial (0/2) ... mse: 0.0565 (8 sec.)\n",
      "sample (4/81) trial (1/2) ... mse: 0.0679 (8 sec.)\n",
      "done sample (4/81) - (avg_mse: 0.0622)\n",
      "training mesh point - (ti: [0.1 0.6]), (di: [2.0702 1.3863])\n",
      "sample (5/81) trial (0/2) ... mse: 0.0017 (5 sec.)\n",
      "sample (5/81) trial (1/2) ... mse: 0.0299 (7 sec.)\n",
      "done sample (5/81) - (avg_mse: 0.0158)\n",
      "training mesh point - (ti: [0.1 0.7]), (di: [2.0702 1.7346])\n",
      "sample (6/81) trial (0/2) ... mse: 0.1289 (6 sec.)\n",
      "sample (6/81) trial (1/2) ... mse: 0.1413 (5 sec.)\n",
      "done sample (6/81) - (avg_mse: 0.1351)\n",
      "training mesh point - (ti: [0.1 0.8]), (di: [2.0702 2.1972])\n",
      "sample (7/81) trial (0/2) ... mse: 0.1125 (9 sec.)\n",
      "sample (7/81) trial (1/2) ... mse: 0.0844 (8 sec.)\n",
      "done sample (7/81) - (avg_mse: 0.0984)\n",
      "training mesh point - (ti: [0.1 0.9]), (di: [2.0702 2.9444])\n",
      "sample (8/81) trial (0/2) ... mse: 0.2434 (7 sec.)\n",
      "sample (8/81) trial (1/2) ... mse: 0.3547 (9 sec.)\n",
      "done sample (8/81) - (avg_mse: 0.2991)\n",
      "training mesh point - (ti: [0.2 0.1]), (di: [2.1445 0.2007])\n",
      "sample (9/81) trial (0/2) ... mse: 0.0410 (6 sec.)\n",
      "sample (9/81) trial (1/2) ... mse: 0.0521 (7 sec.)\n",
      "done sample (9/81) - (avg_mse: 0.0465)\n",
      "training mesh point - (ti: [0.2 0.2]), (di: [2.1445 0.4055])\n",
      "sample (10/81) trial (0/2) ... mse: 0.0044 (7 sec.)\n",
      "sample (10/81) trial (1/2) ... mse: 0.0230 (7 sec.)\n",
      "done sample (10/81) - (avg_mse: 0.0137)\n",
      "training mesh point - (ti: [0.2 0.3]), (di: [2.1445 0.619 ])\n",
      "sample (11/81) trial (0/2) ... mse: 0.0261 (7 sec.)\n",
      "sample (11/81) trial (1/2) ... mse: 0.0209 (4 sec.)\n",
      "done sample (11/81) - (avg_mse: 0.0235)\n",
      "training mesh point - (ti: [0.2 0.4]), (di: [2.1445 0.8473])\n",
      "sample (12/81) trial (0/2) ... mse: 0.0986 (5 sec.)\n",
      "sample (12/81) trial (1/2) ... mse: 0.0647 (8 sec.)\n",
      "done sample (12/81) - (avg_mse: 0.0817)\n",
      "training mesh point - (ti: [0.2 0.5]), (di: [2.1445 1.0986])\n",
      "sample (13/81) trial (0/2) ... mse: 0.2689 (11 sec.)\n",
      "sample (13/81) trial (1/2) ... mse: 0.0391 (9 sec.)\n",
      "done sample (13/81) - (avg_mse: 0.1540)\n",
      "training mesh point - (ti: [0.2 0.6]), (di: [2.1445 1.3863])\n",
      "sample (14/81) trial (0/2) ... mse: 0.0447 (7 sec.)\n",
      "sample (14/81) trial (1/2) ... mse: 0.0415 (9 sec.)\n",
      "done sample (14/81) - (avg_mse: 0.0431)\n",
      "training mesh point - (ti: [0.2 0.7]), (di: [2.1445 1.7346])\n",
      "sample (15/81) trial (0/2) ... mse: 0.1233 (6 sec.)\n",
      "sample (15/81) trial (1/2) ... mse: 0.1719 (9 sec.)\n",
      "done sample (15/81) - (avg_mse: 0.1476)\n",
      "training mesh point - (ti: [0.2 0.8]), (di: [2.1445 2.1972])\n",
      "sample (16/81) trial (0/2) ... mse: 0.0543 (6 sec.)\n",
      "sample (16/81) trial (1/2) ... mse: 0.0231 (7 sec.)\n",
      "done sample (16/81) - (avg_mse: 0.0387)\n",
      "training mesh point - (ti: [0.2 0.9]), (di: [2.1445 2.9444])\n",
      "sample (17/81) trial (0/2) ... mse: 0.0647 (11 sec.)\n",
      "sample (17/81) trial (1/2) ... mse: 0.0954 (21 sec.)\n",
      "done sample (17/81) - (avg_mse: 0.0800)\n",
      "training mesh point - (ti: [0.3 0.1]), (di: [2.2234 0.2007])\n",
      "sample (18/81) trial (0/2) ... mse: 0.0686 (10 sec.)\n",
      "sample (18/81) trial (1/2) ... mse: 0.2835 (8 sec.)\n",
      "done sample (18/81) - (avg_mse: 0.1760)\n",
      "training mesh point - (ti: [0.3 0.2]), (di: [2.2234 0.4055])\n",
      "sample (19/81) trial (0/2) ... mse: 0.0363 (7 sec.)\n",
      "sample (19/81) trial (1/2) ... mse: 0.0995 (6 sec.)\n",
      "done sample (19/81) - (avg_mse: 0.0679)\n",
      "training mesh point - (ti: [0.3 0.3]), (di: [2.2234 0.619 ])\n",
      "sample (20/81) trial (0/2) ... mse: 0.1454 (7 sec.)\n",
      "sample (20/81) trial (1/2) ... mse: 0.0734 (8 sec.)\n",
      "done sample (20/81) - (avg_mse: 0.1094)\n",
      "training mesh point - (ti: [0.3 0.4]), (di: [2.2234 0.8473])\n",
      "sample (21/81) trial (0/2) ... mse: 0.1068 (5 sec.)\n",
      "sample (21/81) trial (1/2) ... mse: 0.1171 (8 sec.)\n",
      "done sample (21/81) - (avg_mse: 0.1119)\n",
      "training mesh point - (ti: [0.3 0.5]), (di: [2.2234 1.0986])\n",
      "sample (22/81) trial (0/2) ... mse: 0.2254 (5 sec.)\n",
      "sample (22/81) trial (1/2) ... mse: 0.0341 (7 sec.)\n",
      "done sample (22/81) - (avg_mse: 0.1297)\n",
      "training mesh point - (ti: [0.3 0.6]), (di: [2.2234 1.3863])\n",
      "sample (23/81) trial (0/2) ... mse: 0.0047 (6 sec.)\n",
      "sample (23/81) trial (1/2) ... mse: 0.0350 (5 sec.)\n",
      "done sample (23/81) - (avg_mse: 0.0199)\n",
      "training mesh point - (ti: [0.3 0.7]), (di: [2.2234 1.7346])\n",
      "sample (24/81) trial (0/2) ... mse: 0.0341 (6 sec.)\n",
      "sample (24/81) trial (1/2) ... mse: 0.0280 (8 sec.)\n",
      "done sample (24/81) - (avg_mse: 0.0311)\n",
      "training mesh point - (ti: [0.3 0.8]), (di: [2.2234 2.1972])\n",
      "sample (25/81) trial (0/2) ... mse: 0.0547 (5 sec.)\n",
      "sample (25/81) trial (1/2) ... mse: 0.1619 (9 sec.)\n",
      "done sample (25/81) - (avg_mse: 0.1083)\n",
      "training mesh point - (ti: [0.3 0.9]), (di: [2.2234 2.9444])\n",
      "sample (26/81) trial (0/2) ... mse: 0.1211 (5 sec.)\n",
      "sample (26/81) trial (1/2) ... mse: 0.1570 (8 sec.)\n",
      "done sample (26/81) - (avg_mse: 0.1390)\n",
      "training mesh point - (ti: [0.4 0.1]), (di: [2.3076 0.2007])\n",
      "sample (27/81) trial (0/2) ... mse: 0.0262 (8 sec.)\n",
      "sample (27/81) trial (1/2) ... mse: 0.0759 (5 sec.)\n",
      "done sample (27/81) - (avg_mse: 0.0510)\n",
      "training mesh point - (ti: [0.4 0.2]), (di: [2.3076 0.4055])\n",
      "sample (28/81) trial (0/2) ... mse: 0.0020 (6 sec.)\n",
      "sample (28/81) trial (1/2) ... mse: 0.0086 (9 sec.)\n",
      "done sample (28/81) - (avg_mse: 0.0053)\n",
      "training mesh point - (ti: [0.4 0.3]), (di: [2.3076 0.619 ])\n",
      "sample (29/81) trial (0/2) ... mse: 0.0122 (6 sec.)\n",
      "sample (29/81) trial (1/2) ... mse: 0.0376 (6 sec.)\n",
      "done sample (29/81) - (avg_mse: 0.0249)\n",
      "training mesh point - (ti: [0.4 0.4]), (di: [2.3076 0.8473])\n",
      "sample (30/81) trial (0/2) ... mse: 0.0257 (5 sec.)\n",
      "sample (30/81) trial (1/2) ... mse: 0.1251 (11 sec.)\n",
      "done sample (30/81) - (avg_mse: 0.0754)\n",
      "training mesh point - (ti: [0.4 0.5]), (di: [2.3076 1.0986])\n",
      "sample (31/81) trial (0/2) ... mse: 0.0430 (5 sec.)\n",
      "sample (31/81) trial (1/2) ... mse: 0.1059 (9 sec.)\n",
      "done sample (31/81) - (avg_mse: 0.0745)\n",
      "training mesh point - (ti: [0.4 0.6]), (di: [2.3076 1.3863])\n",
      "sample (32/81) trial (0/2) ... mse: 0.0130 (10 sec.)\n",
      "sample (32/81) trial (1/2) ... mse: 0.0415 (5 sec.)\n",
      "done sample (32/81) - (avg_mse: 0.0273)\n",
      "training mesh point - (ti: [0.4 0.7]), (di: [2.3076 1.7346])\n",
      "sample (33/81) trial (0/2) ... mse: 0.0266 (5 sec.)\n",
      "sample (33/81) trial (1/2) ... mse: 0.0747 (7 sec.)\n",
      "done sample (33/81) - (avg_mse: 0.0506)\n",
      "training mesh point - (ti: [0.4 0.8]), (di: [2.3076 2.1972])\n",
      "sample (34/81) trial (0/2) ... mse: 0.0102 (7 sec.)\n",
      "sample (34/81) trial (1/2) ... mse: 0.0524 (6 sec.)\n",
      "done sample (34/81) - (avg_mse: 0.0313)\n",
      "training mesh point - (ti: [0.4 0.9]), (di: [2.3076 2.9444])\n",
      "sample (35/81) trial (0/2) ... mse: 0.1368 (10 sec.)\n",
      "sample (35/81) trial (1/2) ... mse: 0.1277 (9 sec.)\n",
      "done sample (35/81) - (avg_mse: 0.1322)\n",
      "training mesh point - (ti: [0.5 0.1]), (di: [2.3981 0.2007])\n",
      "sample (36/81) trial (0/2) ... mse: 0.1413 (8 sec.)\n",
      "sample (36/81) trial (1/2) ... mse: 0.0290 (8 sec.)\n",
      "done sample (36/81) - (avg_mse: 0.0851)\n",
      "training mesh point - (ti: [0.5 0.2]), (di: [2.3981 0.4055])\n",
      "sample (37/81) trial (0/2) ... mse: 0.0362 (6 sec.)\n",
      "sample (37/81) trial (1/2) ... mse: 0.0264 (8 sec.)\n",
      "done sample (37/81) - (avg_mse: 0.0313)\n",
      "training mesh point - (ti: [0.5 0.3]), (di: [2.3981 0.619 ])\n",
      "sample (38/81) trial (0/2) ... mse: 0.0556 (6 sec.)\n",
      "sample (38/81) trial (1/2) ... mse: 0.0093 (5 sec.)\n",
      "done sample (38/81) - (avg_mse: 0.0324)\n",
      "training mesh point - (ti: [0.5 0.4]), (di: [2.3981 0.8473])\n",
      "sample (39/81) trial (0/2) ... mse: 0.0604 (7 sec.)\n",
      "sample (39/81) trial (1/2) ... mse: 0.0630 (4 sec.)\n",
      "done sample (39/81) - (avg_mse: 0.0617)\n",
      "training mesh point - (ti: [0.5 0.5]), (di: [2.3981 1.0986])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample (40/81) trial (0/2) ... mse: 0.0386 (13 sec.)\n",
      "sample (40/81) trial (1/2) ... mse: 0.0393 (8 sec.)\n",
      "done sample (40/81) - (avg_mse: 0.0389)\n",
      "training mesh point - (ti: [0.5 0.6]), (di: [2.3981 1.3863])\n",
      "sample (41/81) trial (0/2) ... mse: 0.0779 (6 sec.)\n",
      "sample (41/81) trial (1/2) ... mse: 0.0076 (8 sec.)\n",
      "done sample (41/81) - (avg_mse: 0.0427)\n",
      "training mesh point - (ti: [0.5 0.7]), (di: [2.3981 1.7346])\n",
      "sample (42/81) trial (0/2) ... mse: 0.0072 (7 sec.)\n",
      "sample (42/81) trial (1/2) ... mse: 0.0324 (6 sec.)\n",
      "done sample (42/81) - (avg_mse: 0.0198)\n",
      "training mesh point - (ti: [0.5 0.8]), (di: [2.3981 2.1972])\n",
      "sample (43/81) trial (0/2) ... mse: 0.0184 (6 sec.)\n",
      "sample (43/81) trial (1/2) ... mse: 0.0514 (5 sec.)\n",
      "done sample (43/81) - (avg_mse: 0.0349)\n",
      "training mesh point - (ti: [0.5 0.9]), (di: [2.3981 2.9444])\n",
      "sample (44/81) trial (0/2) ... mse: 0.1099 (7 sec.)\n",
      "sample (44/81) trial (1/2) ... mse: 0.0798 (8 sec.)\n",
      "done sample (44/81) - (avg_mse: 0.0949)\n",
      "training mesh point - (ti: [0.6 0.1]), (di: [2.496  0.2007])\n",
      "sample (45/81) trial (0/2) ... mse: 0.0621 (8 sec.)\n",
      "sample (45/81) trial (1/2) ... mse: 0.0487 (6 sec.)\n",
      "done sample (45/81) - (avg_mse: 0.0554)\n",
      "training mesh point - (ti: [0.6 0.2]), (di: [2.496  0.4055])\n",
      "sample (46/81) trial (0/2) ... mse: 0.0197 (6 sec.)\n",
      "sample (46/81) trial (1/2) ... mse: 0.0017 (7 sec.)\n",
      "done sample (46/81) - (avg_mse: 0.0107)\n",
      "training mesh point - (ti: [0.6 0.3]), (di: [2.496 0.619])\n",
      "sample (47/81) trial (0/2) ... mse: 0.0132 (11 sec.)\n",
      "sample (47/81) trial (1/2) ... mse: 0.0078 (7 sec.)\n",
      "done sample (47/81) - (avg_mse: 0.0105)\n",
      "training mesh point - (ti: [0.6 0.4]), (di: [2.496  0.8473])\n",
      "sample (48/81) trial (0/2) ... mse: 0.0720 (5 sec.)\n",
      "sample (48/81) trial (1/2) ... mse: 0.1374 (5 sec.)\n",
      "done sample (48/81) - (avg_mse: 0.1047)\n",
      "training mesh point - (ti: [0.6 0.5]), (di: [2.496  1.0986])\n",
      "sample (49/81) trial (0/2) ... mse: 0.2038 (5 sec.)\n",
      "sample (49/81) trial (1/2) ... mse: 0.1115 (6 sec.)\n",
      "done sample (49/81) - (avg_mse: 0.1576)\n",
      "training mesh point - (ti: [0.6 0.6]), (di: [2.496  1.3863])\n",
      "sample (50/81) trial (0/2) ... mse: 0.0153 (5 sec.)\n",
      "sample (50/81) trial (1/2) ... mse: 0.0124 (8 sec.)\n",
      "done sample (50/81) - (avg_mse: 0.0139)\n",
      "training mesh point - (ti: [0.6 0.7]), (di: [2.496  1.7346])\n",
      "sample (51/81) trial (0/2) ... mse: 0.0560 (8 sec.)\n",
      "sample (51/81) trial (1/2) ... mse: 0.1122 (6 sec.)\n",
      "done sample (51/81) - (avg_mse: 0.0841)\n",
      "training mesh point - (ti: [0.6 0.8]), (di: [2.496  2.1972])\n",
      "sample (52/81) trial (0/2) ... mse: 0.3010 (5 sec.)\n",
      "sample (52/81) trial (1/2) ... mse: 0.0359 (11 sec.)\n",
      "done sample (52/81) - (avg_mse: 0.1685)\n",
      "training mesh point - (ti: [0.6 0.9]), (di: [2.496  2.9444])\n",
      "sample (53/81) trial (0/2) ... mse: 0.6251 (12 sec.)\n",
      "sample (53/81) trial (1/2) ... mse: 0.0937 (7 sec.)\n",
      "done sample (53/81) - (avg_mse: 0.3594)\n",
      "training mesh point - (ti: [0.7 0.1]), (di: [2.6028 0.2007])\n",
      "sample (54/81) trial (0/2) ... mse: 0.0716 (5 sec.)\n",
      "sample (54/81) trial (1/2) ... mse: 0.1030 (7 sec.)\n",
      "done sample (54/81) - (avg_mse: 0.0873)\n",
      "training mesh point - (ti: [0.7 0.2]), (di: [2.6028 0.4055])\n",
      "sample (55/81) trial (0/2) ... mse: 0.0256 (6 sec.)\n",
      "sample (55/81) trial (1/2) ... mse: 0.0868 (7 sec.)\n",
      "done sample (55/81) - (avg_mse: 0.0562)\n",
      "training mesh point - (ti: [0.7 0.3]), (di: [2.6028 0.619 ])\n",
      "sample (56/81) trial (0/2) ... mse: 0.0779 (6 sec.)\n",
      "sample (56/81) trial (1/2) ... mse: 0.0351 (7 sec.)\n",
      "done sample (56/81) - (avg_mse: 0.0565)\n",
      "training mesh point - (ti: [0.7 0.4]), (di: [2.6028 0.8473])\n",
      "sample (57/81) trial (0/2) ... mse: 0.0671 (11 sec.)\n",
      "sample (57/81) trial (1/2) ... mse: 0.1555 (7 sec.)\n",
      "done sample (57/81) - (avg_mse: 0.1113)\n",
      "training mesh point - (ti: [0.7 0.5]), (di: [2.6028 1.0986])\n",
      "sample (58/81) trial (0/2) ... mse: 0.0457 (6 sec.)\n",
      "sample (58/81) trial (1/2) ... mse: 0.0551 (11 sec.)\n",
      "done sample (58/81) - (avg_mse: 0.0504)\n",
      "training mesh point - (ti: [0.7 0.6]), (di: [2.6028 1.3863])\n",
      "sample (59/81) trial (0/2) ... mse: 0.0674 (10 sec.)\n",
      "sample (59/81) trial (1/2) ... mse: 0.0097 (9 sec.)\n",
      "done sample (59/81) - (avg_mse: 0.0385)\n",
      "training mesh point - (ti: [0.7 0.7]), (di: [2.6028 1.7346])\n",
      "sample (60/81) trial (0/2) ... mse: 0.0308 (9 sec.)\n",
      "sample (60/81) trial (1/2) ... mse: 0.0461 (5 sec.)\n",
      "done sample (60/81) - (avg_mse: 0.0385)\n",
      "training mesh point - (ti: [0.7 0.8]), (di: [2.6028 2.1972])\n",
      "sample (61/81) trial (0/2) ... mse: 0.0092 (7 sec.)\n",
      "sample (61/81) trial (1/2) ... mse: 0.0425 (8 sec.)\n",
      "done sample (61/81) - (avg_mse: 0.0259)\n",
      "training mesh point - (ti: [0.7 0.9]), (di: [2.6028 2.9444])\n",
      "sample (62/81) trial (0/2) ... mse: 0.3737 (10 sec.)\n",
      "sample (62/81) trial (1/2) ... mse: 0.0712 (5 sec.)\n",
      "done sample (62/81) - (avg_mse: 0.2224)\n",
      "training mesh point - (ti: [0.8 0.1]), (di: [2.7204 0.2007])\n",
      "sample (63/81) trial (0/2) ... mse: 0.0845 (5 sec.)\n",
      "sample (63/81) trial (1/2) ... mse: 0.0475 (8 sec.)\n",
      "done sample (63/81) - (avg_mse: 0.0660)\n",
      "training mesh point - (ti: [0.8 0.2]), (di: [2.7204 0.4055])\n",
      "sample (64/81) trial (0/2) ... mse: 0.0256 (6 sec.)\n",
      "sample (64/81) trial (1/2) ... mse: 0.0738 (8 sec.)\n",
      "done sample (64/81) - (avg_mse: 0.0497)\n",
      "training mesh point - (ti: [0.8 0.3]), (di: [2.7204 0.619 ])\n",
      "sample (65/81) trial (0/2) ... mse: 0.0362 (8 sec.)\n",
      "sample (65/81) trial (1/2) ... mse: 0.0274 (4 sec.)\n",
      "done sample (65/81) - (avg_mse: 0.0318)\n",
      "training mesh point - (ti: [0.8 0.4]), (di: [2.7204 0.8473])\n",
      "sample (66/81) trial (0/2) ... mse: 0.0929 (10 sec.)\n",
      "sample (66/81) trial (1/2) ... mse: 0.2733 (5 sec.)\n",
      "done sample (66/81) - (avg_mse: 0.1831)\n",
      "training mesh point - (ti: [0.8 0.5]), (di: [2.7204 1.0986])\n",
      "sample (67/81) trial (0/2) ... mse: 0.0286 (7 sec.)\n",
      "sample (67/81) trial (1/2) ... mse: 0.0511 (8 sec.)\n",
      "done sample (67/81) - (avg_mse: 0.0398)\n",
      "training mesh point - (ti: [0.8 0.6]), (di: [2.7204 1.3863])\n",
      "sample (68/81) trial (0/2) ... mse: 0.0283 (7 sec.)\n",
      "sample (68/81) trial (1/2) ... mse: 0.0664 (12 sec.)\n",
      "done sample (68/81) - (avg_mse: 0.0473)\n",
      "training mesh point - (ti: [0.8 0.7]), (di: [2.7204 1.7346])\n",
      "sample (69/81) trial (0/2) ... mse: 0.1089 (7 sec.)\n",
      "sample (69/81) trial (1/2) ... mse: 0.0180 (9 sec.)\n",
      "done sample (69/81) - (avg_mse: 0.0635)\n",
      "training mesh point - (ti: [0.8 0.8]), (di: [2.7204 2.1972])\n",
      "sample (70/81) trial (0/2) ... mse: 0.0660 (10 sec.)\n",
      "sample (70/81) trial (1/2) ... mse: 0.1602 (4 sec.)\n",
      "done sample (70/81) - (avg_mse: 0.1131)\n",
      "training mesh point - (ti: [0.8 0.9]), (di: [2.7204 2.9444])\n",
      "sample (71/81) trial (0/2) ... mse: 0.0717 (9 sec.)\n",
      "sample (71/81) trial (1/2) ... mse: 0.1575 (11 sec.)\n",
      "done sample (71/81) - (avg_mse: 0.1146)\n",
      "training mesh point - (ti: [0.9 0.1]), (di: [2.8515 0.2007])\n",
      "sample (72/81) trial (0/2) ... mse: 0.0627 (5 sec.)\n",
      "sample (72/81) trial (1/2) ... mse: 0.0612 (9 sec.)\n",
      "done sample (72/81) - (avg_mse: 0.0620)\n",
      "training mesh point - (ti: [0.9 0.2]), (di: [2.8515 0.4055])\n",
      "sample (73/81) trial (0/2) ... mse: 0.0841 (7 sec.)\n",
      "sample (73/81) trial (1/2) ... mse: 0.0644 (6 sec.)\n",
      "done sample (73/81) - (avg_mse: 0.0742)\n",
      "training mesh point - (ti: [0.9 0.3]), (di: [2.8515 0.619 ])\n",
      "sample (74/81) trial (0/2) ... mse: 0.0698 (5 sec.)\n",
      "sample (74/81) trial (1/2) ... mse: 0.1223 (6 sec.)\n",
      "done sample (74/81) - (avg_mse: 0.0961)\n",
      "training mesh point - (ti: [0.9 0.4]), (di: [2.8515 0.8473])\n",
      "sample (75/81) trial (0/2) ... mse: 0.1633 (10 sec.)\n",
      "sample (75/81) trial (1/2) ... mse: 0.1708 (5 sec.)\n",
      "done sample (75/81) - (avg_mse: 0.1671)\n",
      "training mesh point - (ti: [0.9 0.5]), (di: [2.8515 1.0986])\n",
      "sample (76/81) trial (0/2) ... mse: 0.0274 (8 sec.)\n",
      "sample (76/81) trial (1/2) ... mse: 0.2480 (10 sec.)\n",
      "done sample (76/81) - (avg_mse: 0.1377)\n",
      "training mesh point - (ti: [0.9 0.6]), (di: [2.8515 1.3863])\n",
      "sample (77/81) trial (0/2) ... mse: 0.0378 (6 sec.)\n",
      "sample (77/81) trial (1/2) ... mse: 0.0068 (6 sec.)\n",
      "done sample (77/81) - (avg_mse: 0.0223)\n",
      "training mesh point - (ti: [0.9 0.7]), (di: [2.8515 1.7346])\n",
      "sample (78/81) trial (0/2) ... mse: 0.0850 (9 sec.)\n",
      "sample (78/81) trial (1/2) ... mse: 0.0013 (6 sec.)\n",
      "done sample (78/81) - (avg_mse: 0.0432)\n",
      "training mesh point - (ti: [0.9 0.8]), (di: [2.8515 2.1972])\n",
      "sample (79/81) trial (0/2) ... mse: 0.0729 (5 sec.)\n",
      "sample (79/81) trial (1/2) ... mse: 0.0704 (5 sec.)\n",
      "done sample (79/81) - (avg_mse: 0.0717)\n",
      "training mesh point - (ti: [0.9 0.9]), (di: [2.8515 2.9444])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample (80/81) trial (0/2) ... mse: 0.2427 (5 sec.)\n",
      "sample (80/81) trial (1/2) ... mse: 0.3502 (8 sec.)\n",
      "done sample (80/81) - (avg_mse: 0.2964)\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "def experiment(dist):\n",
    "    \n",
    "    N = 1000\n",
    "    M = 256\n",
    "    f = dist['sample']\n",
    "    ranges = dist['ranges']\n",
    "#     NUM_LEARNING_EXPERIMENTS = 10\n",
    "    NUM_LEARNING_EXPERIMENTS = 2\n",
    "\n",
    "    # create a mesh on the unit square, with a resolution of 0.1 (0.1,0.2,...,0.9)\n",
    "    # The mesh is a cube of size 9^n_params (e.g., 9^2 for 2 params)\n",
    "    n_params = ranges.shape[0]\n",
    "    resolusion = np.arange(start=0.1, stop=1.0, step=0.1)\n",
    "    resolusion = np.around(resolusion, decimals=1)\n",
    "    n = len(resolusion)\n",
    "    mesh = np.zeros(shape=[n]*n_params, dtype=float)\n",
    "\n",
    "    # create range adjusters for each parameter range\n",
    "    param_adjusters = [adjuster_logit(low=r[0], high=r[1]) for r in ranges]\n",
    "\n",
    "    # - for each cell in the mesh create a sample using the corresponfing cell params.\n",
    "    #   - adjust parameters in each cell using the appropriate adjuster for each parameter.\n",
    "    mesh_samples = []\n",
    "    mesh_params_ti = []\n",
    "    mesh_params_di = []\n",
    "    for idx in np.ndindex(mesh.shape):\n",
    "        ti = (np.array(idx)+1)/(n+1)\n",
    "        di = np.zeros_like(ti)\n",
    "        for i in range(n_params):\n",
    "            di[i] = param_adjusters[i](ti[i])\n",
    "        sample = f(di, size=M)\n",
    "        mesh_samples.append(sample)\n",
    "        mesh_params_ti.append(ti)\n",
    "        mesh_params_di.append(di)\n",
    "    \n",
    "    # For each point in the mesh:\n",
    "    # - Run learning experiment producing several (say 10-100) learning experiments.\n",
    "    # - Compute the average error of the 10-100 experiments. MSE rules\n",
    "    # - Compute the Cramer Rao bound (numerically if the analytical solution is not possible)\n",
    "    # - Divide the MSE by Cramer Rao.\n",
    "    \n",
    "    num_samples = len(mesh_samples)\n",
    "    \n",
    "    mesh_points_cache = MeshPointsCache(path='cached_mesh_points.csv')\n",
    "\n",
    "    mesh_errors = np.zeros(shape=(num_samples,), dtype=float)\n",
    "    for i, sample in enumerate(mesh_samples):\n",
    "               \n",
    "        avg_mse = 0\n",
    "\n",
    "        print(f'training mesh point - (ti: {mesh_params_ti[i]}), (di: {mesh_params_di[i]})')\n",
    "        \n",
    "        # skip cached mesh points\n",
    "        cached_avg_mse = mesh_points_cache.get_mse(mesh_params_ti[i])\n",
    "        if cached_avg_mse:\n",
    "            # value is mse\n",
    "            mesh_errors[i] = cached_avg_mse\n",
    "            print(f'sample ({i}/{num_samples}) loaded from cache (mse: {cached_avg_mse:.4f})')\n",
    "            continue\n",
    "        \n",
    "        for j in range(NUM_LEARNING_EXPERIMENTS):\n",
    "            \n",
    "            start = timer()\n",
    "            \n",
    "            # generate training data\n",
    "            samples_train, params_train, H_train = generate_data(N=N, M=M, f=f, ranges=ranges)\n",
    "            \n",
    "            print(f'sample ({i}/{num_samples}) trial ({j}/{NUM_LEARNING_EXPERIMENTS}) ...', end=' ')\n",
    "            \n",
    "            # fit DNN model to the training data           \n",
    "            dnn_model, history = fit_dnn_model(X_train=H_train, y_train=params_train)\n",
    "\n",
    "            # create test data (a histogram generated from the sample at mesh point)\n",
    "            nbins = H_train.shape[1]\n",
    "            H_test = np.histogram(sample, bins=nbins, range=(0, nbins), density=False)[0]\n",
    "            H_test = H_test.reshape((1,-1))\n",
    "            \n",
    "            # predict sample parameters\n",
    "            params_test = mesh_params_di[i].reshape((1,-1))\n",
    "            y_pred, mse = predict(dnn_model, X_test=H_test, y_test=params_test)\n",
    "            \n",
    "            # average mse (accumulator)\n",
    "            avg_mse += mse\n",
    "            print(f'mse: {mse:.4f} ({int(timer()-start)} sec.)')\n",
    "        \n",
    "        # average mse for sample[i] predictions\n",
    "        avg_mse /= NUM_LEARNING_EXPERIMENTS\n",
    "        mesh_errors[i] = avg_mse\n",
    "        print(f'done sample ({i}/{num_samples}) - (avg_mse: {avg_mse:.4f})')\n",
    "        \n",
    "        # update sample cache\n",
    "        mesh_points_cache.add(ti=mesh_params_ti[i], mse=avg_mse)\n",
    "\n",
    "experiment(dist['yulesimon'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ou",
   "language": "python",
   "name": "ou"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
