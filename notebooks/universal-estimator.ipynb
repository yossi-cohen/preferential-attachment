{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "635cf32d",
   "metadata": {},
   "source": [
    "# Build the 2D universal estimator\n",
    "Input: two (one) dimensional function $f$ that gives the $PMF$ of a univariate distribution.\n",
    "\n",
    "> $x = f(d_1, d_2)$\n",
    "\n",
    "In Python, this comes as a simple function from $Real*Real$ to $Real[0,1]$, case in point: log-normal function.\n",
    "\n",
    "``` python\n",
    "\n",
    "def universal(f, data):\n",
    "    def g(d1, d2):\n",
    "        \"\"\" g is only defined in the cube (-pi/2, pi/2)^2 \"\"\"\n",
    "        return f(tan(d1), tan(d2))\n",
    "\n",
    "    # universal(g) { // Learn d1 and d2, of g, from the data.\n",
    "    # -1. Set U = cube (-pi/2, pi2/2)^2\n",
    "    #  0. Pick the number of sample points; should not be too large...  256 maybe.\n",
    "    #  1. Generate a dense coverage of the cube.\n",
    "    #  2. Generate the data for each point in the sample of the parameter space.\n",
    "    #  3. Apply DNN to find out d1 and d2, for the input data, this may be the final result\n",
    "    #  4. Set the cube to a cube of half the volume.\n",
    "    #  5. forget all that you learned.\n",
    "    #  6. Repeat from step 1, if the volume of the cube is greater than 1/128 of the original cube.\n",
    "    # return the estimate found in the last step 3 above.\n",
    "               \n",
    "```\n",
    "\n",
    "Algorithm:\n",
    "\n",
    "1. Transform the parameter space to unit cube of dimension n=1,2, e.g., (1+ arctan(t))/2, sigmoid.\n",
    "2. Learn the Sigmoid(t1), Sigmoid(t2) (optional: learn t1,t2, not their sigmoid) using the usual statistical method of generating synthetic data.\n",
    "3. Compute the variance of the error of learning, it is typically a function of t1, t2, e.g., the error is not the same everywhere.\n",
    "4. Compute the fisher information: Log, Derivate, Square (analytically), integrate (numerically) over x, ranging over all reals.\n",
    "5. Multiply by n (the number of sample points).\n",
    "6. Compute the inverse.\n",
    "7. Compare to the actual error from (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f29c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "%run lib.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baacd167",
   "metadata": {},
   "source": [
    "## Universal estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e99d9d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def universal_estimator(dist_name, sample_generator, next_config, param_space, N=10000, M=256):\n",
    "\n",
    "    # generate data\n",
    "    print(f'generating {dist_name} data (M={M}, N={N}) param-space: {param_space} ... ', end='')\n",
    "    raw, H, params = generate_data(N=N, \n",
    "                                   M=M, \n",
    "                                   sample=sample_generator, \n",
    "                                   nextConfig=lambda: next_config(param_space),\n",
    "                                   density=False, \n",
    "                                   dense_histogram=True, \n",
    "                                   apply_log_scale=False)\n",
    "    \n",
    "    H_train, H_test, params_train, params_test = train_test_split(H, \n",
    "                                                                    params, \n",
    "                                                                    test_size=0.25, \n",
    "                                                                    random_state=RANDOM_STATE)\n",
    "    print(f'histogram shape: {H_train.shape}')\n",
    "\n",
    "    # fit model to train data\n",
    "    print(f'fitting dnn model ... ', end='')\n",
    "    start_time = time.time()\n",
    "    dnn_model, history = dnn_fit(X_train=H_train, y_train=params_train)\n",
    "    train_time = round(time.time() - start_time)\n",
    "    print(f'duration: {round(train_time)} sec.')\n",
    "\n",
    "    # predict params on test data\n",
    "    print(f'predicting distribution params ... ', end='')\n",
    "    params_pred, sqrt_mse = dnn_predict(dnn_model, H_test, params_test)\n",
    "    print(f'sqrt_mse: {sqrt_mse:.6f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd15e8eb",
   "metadata": {},
   "source": [
    "## Fit (lognormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1424b635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating lognormal data (M=256, N=10000) param-space: [(0.0, 1.0)] ... histogram shape: (7500, 111)\n",
      "fitting dnn model ... "
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats import lognorm\n",
    "\n",
    "# Generate data (lognormal)\n",
    "def lognormal_sample(config, size):\n",
    "    return lognorm.rvs(s=config, size=size, random_state=RANDOM_STATE)\n",
    "\n",
    "def lognormal_next_config(param_space):\n",
    "    min_s = param_space[0][0]\n",
    "    max_s = param_space[0][1]\n",
    "    if None != RS:\n",
    "        return RS.uniform(low=min_s, high=max_s, size=1)[0]\n",
    "    return np.random.uniform(low=min_s, high=max_s, size=1)[0]\n",
    "\n",
    "# Fit (lognormal)\n",
    "universal_estimator(dist_name='lognormal', \n",
    "                    sample_generator=lognormal_sample, \n",
    "                    next_config=lognormal_next_config,\n",
    "                    param_space=[(0.0, 1.0)], \n",
    "                    N=10000, \n",
    "                    M=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be606147",
   "metadata": {},
   "source": [
    "generating lognormal data (M=256, N=10) param-space: [(0.0, 1.0)] ... histogram shape: (7, 12)  \n",
    "fitting dnn model ... duration: 7 sec.  \n",
    "predicting distribution params ... sqrt_mse: 0.397776"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ou",
   "language": "python",
   "name": "ou"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
