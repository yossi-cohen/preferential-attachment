{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "635cf32d",
   "metadata": {},
   "source": [
    "# universal estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5ccd46",
   "metadata": {},
   "source": [
    "### Exp-1: Show that the error decreases when the parameter search space gets smaller.\n",
    "\n",
    "**Research question**:\n",
    "Is the search space size of the parameter $d$ of a univariate distribution $f(d)$ has an affect on the learning and the prediction errors?\n",
    "\n",
    "Let $f(d)$ be a one dimensional function, that returns a samples vector drawn from a univariate distribution (e.g., log-normal).\n",
    "\n",
    "1. Generate a (256) samples vector using e.g: data = f(d=0.92)\n",
    "2. Write a function: $estimator(f, data)$ which learns the parameter $d$ of $f$ from the $data$.\n",
    "\n",
    "> - Init: search_space = (0,1)\n",
    "> - Iterate (stop when the search-space size reaches some fraction, e.g. 1/128, of the initial search space)\n",
    ">   1. Generate synthetic data-sets ( train / test ) using $f$ (within the parameter search space)\n",
    ">   2. Fit a DNN model, error = | pred-set - test-set |\n",
    ">   3. Predict the parameter $d\\_pred$ on the input data\n",
    ">   4. Narrow the search space:\n",
    ">           pivot = d_pred\n",
    ">           margin = 2 * std(error)\n",
    ">           search_space = ( pivot - margin, pivot  + margin )\n",
    "\n",
    "3. Plot a graph:\n",
    "   - $x$: size of search space\n",
    "   - $y$: error\n",
    "   - show that the size of the error converges to a lower limit (asymptotically)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f29c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "%run lib.ipynb\n",
    "np.set_printoptions(precision=4)\n",
    "reset_random_state(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2761a92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_config(param_search_space):\n",
    "    \"\"\"\n",
    "    return a random (uniform)parameter within param_search_space\n",
    "    \"\"\"\n",
    "    low = param_search_space[0]\n",
    "    high = param_search_space[1]\n",
    "    if None != RS:\n",
    "        return RS.uniform(low, high, size=1)[0]\n",
    "    return np.random.uniform(low, high, size=1)[0]\n",
    "\n",
    "def estimator_exp_1(f, data, d_true,\n",
    "                    initial_param_search_space=np.array([0.0,1.0])):\n",
    "    \"\"\"\n",
    "    Learn parameters of f, from the data.\n",
    "    Arguments:\n",
    "        - f: one dimensional function that gives the PMF of a univariate distribution.\n",
    "        - data: samplesarray generated using f.\n",
    "    \"\"\"\n",
    "\n",
    "    # experiment result: [ (size of search space, test_MAE) ]\n",
    "    res = {\n",
    "        'search_space_width': [],\n",
    "        'test_MAE': [],\n",
    "        'd_pred_MAE': [],\n",
    "        'd_pred_best_MAE': [],\n",
    "        'd_pred': 0,\n",
    "        'd_pred_best': 0,\n",
    "    }\n",
    "   \n",
    "    # number of samples in data\n",
    "    M = len(data)\n",
    "    N = 1000\n",
    "\n",
    "    d_pred_best = -1\n",
    "    data_MAE_best = -1\n",
    "    \n",
    "    # Iterate\n",
    "    param_search_space = initial_param_search_space\n",
    "    while True:\n",
    "        \n",
    "        # 1. Generate synthetic learning data-sets (train/test) using f (within param_search_space)\n",
    "        # -----------------------------------------------------------------------------------------\n",
    "        print()\n",
    "        print(f'generating data (M={M}, N={N}) param_search_space: {param_search_space} ...', end=' ')\n",
    "        raw, H, params = generate_data(N=N, \n",
    "                                       M=M, \n",
    "                                       sample=f, \n",
    "                                       nextConfig=lambda: next_config(param_search_space),\n",
    "                                       density=False, \n",
    "                                       apply_log_scale=False)\n",
    "\n",
    "        H_train, H_test, train_params, test_params = train_test_split(H, \n",
    "                                                                      params, \n",
    "                                                                      test_size=0.25, \n",
    "                                                                      random_state=RANDOM_STATE)\n",
    "        print(f'histogram shape: {H_train.shape}')\n",
    "\n",
    "        # 2. Fit a DNN model to train-set and predict on test-set, error = | pred-set - test-set |\n",
    "        # -----------------------------------------------------------------------------------------\n",
    "        \n",
    "        print(f'fitting dnn model ...', end=' ')\n",
    "        start_time = time.time()\n",
    "        dnn_model, history = dnn_fit(X_train=H_train, y_train=train_params)\n",
    "        train_time = time.time() - start_time\n",
    "\n",
    "        test_pred = dnn_model.predict(H_test).flatten()\n",
    "        test_MAE = mean_absolute_error(test_params, test_pred)\n",
    "        print(f'test_MAE: {test_MAE:.4f}', end=', ')\n",
    "\n",
    "        # 3. Predict the parameter d on the input data (d_pred)\n",
    "        # -----------------------------------------------------------------------------------------\n",
    "\n",
    "        nbins = H_train.shape[1]\n",
    "        h_data = np.histogram(data, bins=nbins, range=(0,nbins), density=False)[0]\n",
    "        h_data = np.reshape(h_data, (1, -1))\n",
    "        d_pred = dnn_model.predict(h_data).flatten()[0]\n",
    "        print(f'd_pred: {d_pred:.4f}, abs(d_pred - d_true): {abs(d_pred - d_true):.4f}')\n",
    "        \n",
    "        #lilo\n",
    "        data_pred = f(d_pred, size=M)\n",
    "        data_MAE = mean_absolute_error(data_pred, data)\n",
    "#         data_pred, _, _ = generate_data(N=10, test_STD_abs_error\n",
    "#                                        M=M, \n",
    "#                                        sample=f, \n",
    "#                                        nextConfig=d_pred,\n",
    "#                                        density=False, \n",
    "#                                        apply_log_scale=False)\n",
    "#         repeat = 100\n",
    "#         data_MAE = np.mean(mean_absolute_error(data_pred, np.repeat(data, repeat).reshape(repeat,-1)))\n",
    "        print(f'data_MAE: {data_MAE:.4f}', end= ', ')\n",
    "        if data_MAE_best < 0 or data_MAE < data_MAE_best:\n",
    "            data_MAE_best = data_MAE\n",
    "            d_pred_best = d_pred\n",
    "        print(f'data_MAE_best: {data_MAE_best:.4f}', end= ', ')\n",
    "        print(f'd_pred_best: {d_pred_best:.4f}')\n",
    "        \n",
    "        # save results\n",
    "        param_search_space_width = param_search_space[1] - param_search_space[0]\n",
    "        res['search_space_width'].append(param_search_space_width)\n",
    "        res['test_MAE'].append(test_MAE)\n",
    "        res['d_pred_MAE'].append(abs(d_pred - d_true))\n",
    "        res['d_pred_best_MAE'].append(abs(d_pred_best - d_true))\n",
    "        res['d_pred'] = d_pred\n",
    "        res['d_pred_best'] = d_pred_best\n",
    "        \n",
    "        # 4. Narrow the search space:\n",
    "        # -----------------------------------------------------------------------------------------\n",
    "        #  - margin = MAE + 2 * std(error)\n",
    "        #  - search_space = [ d_pred - margin, d_pred + margin]\n",
    "        \n",
    "        #lilo:\n",
    "        test_STD_abs_error = np.std( np.abs(test_params, test_pred) )\n",
    "#         margin_std_factor = 1\n",
    "        margin_std_factor = 3\n",
    "        margin = margin_std_factor * test_STD_abs_error\n",
    "        #margin = test_STD_abs_error\n",
    "        \n",
    "        #pivot = d_pred_best\n",
    "        #print(f'pivot=d_pred_best: {pivot:.4f}, margin={margin_std_factor}*test_STD_abs_error: {margin:.4f}')\n",
    "        pivot = d_pred\n",
    "        print(f'pivot=d_pred: {pivot:.4f}, margin={margin_std_factor}*test_STD_abs_error: {margin:.4f}')\n",
    "        \n",
    "        next_search_space = np.array([ \n",
    "            max(param_search_space[0], pivot - margin), \n",
    "            min(param_search_space[1], pivot + margin)])\n",
    "#         next_search_space = np.array([ \n",
    "#             max(initial_param_search_space[0], pivot - margin), \n",
    "#             min(initial_param_search_space[1], pivot + margin)])\n",
    "        \n",
    "        if np.array_equal(param_search_space, next_search_space):\n",
    "            # if no change in param_search_space, narrow by epsilon (from both sides)\n",
    "            epsilon = 0.001\n",
    "#             epsilon = test_STD_abs_error\n",
    "#             epsilon = 0.1 * test_STD_abs_error\n",
    "            print(f'no change in param_search_space. narrowing by epsilon: {epsilon:.4f}')\n",
    "            param_search_space = np.array([param_search_space[0] + epsilon, param_search_space[1] - epsilon])\n",
    "        else:\n",
    "            count_no_change_in_search_space = 0\n",
    "            param_search_space = next_search_space\n",
    "        \n",
    "        # stop condition ?\n",
    "        # size of the search-space (high-low) is 1/128 of the original\n",
    "        # -----------------------------------------------------------------------------------------\n",
    "        \n",
    "        initial_param_search_space_width = initial_param_search_space[1] - initial_param_search_space[0]\n",
    "#         if param_search_space_width < 1/128 * initial_param_search_space_width:\n",
    "        if param_search_space_width < 1/16 * initial_param_search_space_width:\n",
    "            print('stop -----------------------------------------------------------------')\n",
    "            print(f'param_search_space_width: {param_search_space_width:.4f}')\n",
    "            print(f'test_MAE: {test_MAE:.4f}')\n",
    "            print(f'd_pred: {d_pred:.4f}, abs(d_pred - d_true): {abs(d_pred - d_true):.4f}')\n",
    "            break\n",
    "            \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebf68ec",
   "metadata": {},
   "source": [
    "### Plot helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc88beef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_search_space_size_vs_error(res):\n",
    "\n",
    "    param_search_space_width = res['search_space_width']\n",
    "    test_MAE = res['test_MAE']\n",
    "    d_pred_MAE = res['d_pred_MAE']\n",
    "    d_pred_best_MAE = res['d_pred_best_MAE']\n",
    "    d_pred = res['d_pred']\n",
    "    d_pred_best = res['d_pred_best']\n",
    "    \n",
    "    title = f'search space vs. error \\n\\\n",
    "    ( d_true={d_true}, d_pred: {d_pred:.4f}, d_pred_best: {d_pred_best:.4f} )'\n",
    "    \n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.title(title)\n",
    "    plt.xlabel('search space')\n",
    "    plt.ylabel('error')\n",
    "\n",
    "    x = param_search_space_width\n",
    "    y = test_MAE\n",
    "    plt.scatter(x, y, zorder=1, s=2, c='blue', label='test_MSE')\n",
    "    plt.plot(x, y, zorder=2, c='blue')\n",
    "\n",
    "    y = d_pred_MAE\n",
    "    plt.scatter(x, y, zorder=1, s=2, c='orange', label='abs(d_pred - d_true)')\n",
    "    plt.plot(x, y, zorder=2, c='orange')\n",
    "    \n",
    "    y = d_pred_best_MAE\n",
    "    plt.scatter(x, y, zorder=1, s=2, c='red', label='abs(d_pred_best - d_true)')\n",
    "    plt.plot(x, y, zorder=2, c='red')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# plot_search_space_size_vs_error(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b402dd",
   "metadata": {},
   "source": [
    "## Fit (lognormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e14faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "param true value: 0.92\n",
      "\n",
      "generating data (M=256, N=1000) param_search_space: [0. 1.] ... histogram shape: (750, 54)\n",
      "fitting dnn model ... test_MAE: 0.0539, d_pred: 0.9804, abs(d_pred - d_true): 0.0604\n",
      "data_MAE: 1.6302, data_MAE_best: 1.6302, d_pred_best: 0.9804\n",
      "pivot=d_pred: 0.9804, margin=3*test_STD_abs_error: 0.8888\n",
      "\n",
      "generating data (M=256, N=1000) param_search_space: [0.0915 1.    ] ... histogram shape: (750, 49)\n",
      "fitting dnn model ... test_MAE: 0.0475, d_pred: 0.8721, abs(d_pred - d_true): 0.0479\n",
      "data_MAE: 1.5366, data_MAE_best: 1.5366, d_pred_best: 0.8721\n",
      "pivot=d_pred: 0.8721, margin=3*test_STD_abs_error: 0.8022\n",
      "no change in param_search_space. narrowing by epsilon: 0.0010\n",
      "\n",
      "generating data (M=256, N=1000) param_search_space: [0.0925 0.999 ] ... histogram shape: (750, 41)\n",
      "fitting dnn model ... test_MAE: 0.0441, d_pred: 0.9793, abs(d_pred - d_true): 0.0593\n",
      "data_MAE: 1.7444, data_MAE_best: 1.5366, d_pred_best: 0.8721\n",
      "pivot=d_pred: 0.9793, margin=3*test_STD_abs_error: 0.8101\n",
      "\n",
      "generating data (M=256, N=1000) param_search_space: [0.1692 0.999 ] ... histogram shape: (750, 65)\n",
      "fitting dnn model ... test_MAE: 0.0453, d_pred: 0.9224, abs(d_pred - d_true): 0.0024\n",
      "data_MAE: 1.5639, data_MAE_best: 1.5366, d_pred_best: 0.8721\n",
      "pivot=d_pred: 0.9224, margin=3*test_STD_abs_error: 0.6849\n",
      "\n",
      "generating data (M=256, N=1000) param_search_space: [0.2375 0.999 ] ... histogram shape: (750, 64)\n",
      "fitting dnn model ... test_MAE: 0.0416, d_pred: 0.8247, abs(d_pred - d_true): 0.0953\n",
      "data_MAE: 1.4912, data_MAE_best: 1.4912, d_pred_best: 0.8247\n",
      "pivot=d_pred: 0.8247, margin=3*test_STD_abs_error: 0.6432\n",
      "no change in param_search_space. narrowing by epsilon: 0.0010\n",
      "\n",
      "generating data (M=256, N=1000) param_search_space: [0.2385 0.998 ] ... histogram shape: (750, 56)\n",
      "fitting dnn model ... test_MAE: 0.0392, d_pred: 0.9250, abs(d_pred - d_true): 0.0050\n",
      "data_MAE: 1.6958, data_MAE_best: 1.4912, d_pred_best: 0.8247\n",
      "pivot=d_pred: 0.9250, margin=3*test_STD_abs_error: 0.6731\n",
      "\n",
      "generating data (M=256, N=1000) param_search_space: [0.2518 0.998 ] ... histogram shape: (750, 51)\n",
      "fitting dnn model ... "
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats import lognorm\n",
    "\n",
    "# reset_random_state(SEED)\n",
    "\n",
    "# sample from lognormal\n",
    "def sample_lognormal(config, size):\n",
    "    return lognorm.rvs(s=config, size=size, random_state=RANDOM_STATE)\n",
    "\n",
    "# Fit (lognormal)\n",
    "# d_true = 0.92\n",
    "# d_true = 0.85\n",
    "# d_true = 0.66\n",
    "# d_true = 0.25\n",
    "\n",
    "for d_true in [0.92, 0.85, 0.66, 0.25]:\n",
    "    print()\n",
    "    print(f'param true value: {d_true}')\n",
    "    data = sample_lognormal(config=d_true, size=256)\n",
    "    res = estimator_exp_1(f=sample_lognormal, data=data, d_true=d_true)\n",
    "    plot_search_space_size_vs_error(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ou",
   "language": "python",
   "name": "ou"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
