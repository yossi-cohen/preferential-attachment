{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_RANGE=[11]; RANDOM_STATES=[17]\n",
    "# N_RANGE=[5,6,7,8,9,10,11]; RANDOM_STATES=[0, 17]\n",
    "N_RANGE=range(5, 12); RANDOM_STATES=[0, 3, 5, 8, 11, 16, 17, 20, 21, 24]\n",
    "\n",
    "RANDOM_ALPHA = True\n",
    "NUM_ZERO_COLUMNS_TO_HSTACK = 10 # effective only if we hstack-zeros (model name ends with _ZEROS)\n",
    "\n",
    "trials_out = {}\n",
    "\n",
    "PLOT_LEARNING_CURVES = True\n",
    "PLOT_INPUT = True\n",
    "\n",
    "RUN_DNN = True\n",
    "RUN_DNN_ZEROS = False\n",
    "RUN_DNN_WIN_SLIDING_AVG = False\n",
    "RUN_DNN_WIN_SLIDING_AVG_ZEROS = False\n",
    "RUN_DNN_SLIDING_SUM = False\n",
    "RUN_DNN_SLIDING_SUM_ZEROS = False\n",
    "RUN_DNN_WIN = False\n",
    "RUN_DNN_WIN_ZEROS = False\n",
    "\n",
    "RUN_CNN = True\n",
    "RUN_CNN_ZEROS = False\n",
    "RUN_CNNM = False\n",
    "\n",
    "TTEST_NUM_TESTS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import function library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run yulesimon-lib.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_summary(trial):\n",
    "    if PLOT_INPUT:\n",
    "        trial_plot_input(trial['input_sample'])\n",
    "    if PLOT_LEARNING_CURVES:\n",
    "        trial_plot_learning_curves(trial)\n",
    "\n",
    "# helper function to plot learning curves for the given trial output\n",
    "def trial_plot_learning_curves(trial):\n",
    "    history_path = '{}.history'.format(trial['base_path'])\n",
    "    history = pickle.load(open(history_path, 'rb'))\n",
    "    plot_learning_curves(history)\n",
    "\n",
    "# helper function to plot input shape\n",
    "def trial_plot_input(x):\n",
    "    z = x.flatten()\n",
    "    _ = plt.scatter(range(len(z)), z, s=5, color=\"blue\", label=\"original\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "\n",
      "input.shape: (10000, 308)\n",
      "N: 32  avg_sqrt_mse = 0.27728\n",
      "\n",
      "input.shape: (10000, 818)\n",
      "N: 64  avg_sqrt_mse = 0.26447\n",
      "\n",
      "input.shape: (10000, 469)\n",
      "N: 128  avg_sqrt_mse = 0.24145\n",
      "\n",
      "input.shape: (10000, 800)\n",
      "N: 256  avg_sqrt_mse = 0.20801\n",
      "\n",
      "input.shape: (10000, 1197)\n",
      "N: 512  avg_sqrt_mse = 0.18233\n",
      "\n",
      "input.shape: (10000, 2645)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if RUN_DNN:\n",
    "    nn = 'DNN'\n",
    "    trials_out[nn] = trial(nn=nn, N_range=N_RANGE, random_states=RANDOM_STATES)\n",
    "    debug_summary(trials_out[nn])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if RUN_DNN_ZEROS:\n",
    "    nn = 'DNN_ZEROS'\n",
    "    trials_out[nn] = trial(nn=nn, N_range=N_RANGE, random_states=RANDOM_STATES)\n",
    "    debug_summary(trials_out[nn])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN sliding-avg test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_moving_avg_test = np.array([ [1,2,3,4,5,6,7], [1,2,3,4,5,6,7] ])\n",
    "\n",
    "print('X_moving_avg_test:')\n",
    "print(X_moving_avg_test)\n",
    "\n",
    "OUT_moving_avg_test, window_sizes = data_hstack_moving_avg(X_moving_avg_test)\n",
    "\n",
    "print()\n",
    "print('window_sizes:', window_sizes)\n",
    "\n",
    "print()\n",
    "print('OUT_moving_avg_test:')\n",
    "print(OUT_moving_avg_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN sliding-avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if RUN_DNN_WIN_SLIDING_AVG:\n",
    "    nn = 'DNN_SLIDING_AVG'\n",
    "    trials_out[nn] = trial(nn=nn, N_range=N_RANGE, random_states=RANDOM_STATES)\n",
    "    debug_summary(trials_out[nn])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN sliding-avg zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if RUN_DNN_WIN_SLIDING_AVG_ZEROS:\n",
    "    nn = 'DNN_SLIDING_AVG'\n",
    "    trials_out[nn] = trial(nn=nn, N_range=N_RANGE, random_states=RANDOM_STATES)\n",
    "    debug_summary(trials_out[nn])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN sliding-sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if RUN_DNN_SLIDING_SUM:\n",
    "    nn = 'DNN_SLIDING_SUM'\n",
    "    trials_out[nn] = trial(nn=nn, N_range=N_RANGE, random_states=RANDOM_STATES)\n",
    "    debug_summary(trials_out[nn])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN sliding-sum zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if RUN_DNN_SLIDING_SUM_ZEROS:\n",
    "    nn = 'DNN_SLIDING_SUM_ZEROS'\n",
    "    trials_out[nn] = trial(nn=nn, N_range=N_RANGE, random_states=RANDOM_STATES)\n",
    "    debug_summary(trials_out[nn])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN win test\n",
    "Test to show that 'data_hstack_win_sum()' is working correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_win_test = np.array([ [1,2,3,4,5,6,7], [1,2,3,4,5,6,7] ])\n",
    "\n",
    "print('X_win_test:')\n",
    "print(X_win_test)\n",
    "\n",
    "OUT_win_test, window_sizes = data_hstack_win_sum(X_win_test)\n",
    "\n",
    "print()\n",
    "print('window_sizes:', window_sizes)\n",
    "\n",
    "print()\n",
    "print('OUT_win_test:')\n",
    "print(OUT_win_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if RUN_DNN_WIN:\n",
    "    nn = 'DNN_WIN'\n",
    "    trials_out[nn] = trial(nn=nn, N_range=N_RANGE, random_states=RANDOM_STATES)\n",
    "    debug_summary(trials_out[nn])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN win zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if RUN_DNN_WIN_ZEROS:\n",
    "    nn = 'DNN_WIN_ZEROS'\n",
    "    trials_out[nn] = trial(nn=nn, N_range=N_RANGE, random_states=RANDOM_STATES)\n",
    "    debug_summary(trials_out[nn])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if RUN_CNN:\n",
    "    nn = 'CNN'\n",
    "    trials_out[nn] = trial(nn=nn, N_range=N_RANGE, random_states=RANDOM_STATES)\n",
    "    debug_summary(trials_out[nn])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if RUN_CNN_ZEROS:\n",
    "    nn = 'CNN_ZEROS'\n",
    "    trials_out[nn] = trial(nn=nn, N_range=N_RANGE, random_states=RANDOM_STATES)\n",
    "    debug_summary(trials_out[nn])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN multi-layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if RUN_CNNM:\n",
    "    nn = 'CNNM'\n",
    "    trials_out[nn] = trial(nn=nn, N_range=N_RANGE, random_states=RANDOM_STATES)\n",
    "    debug_summary(trials_out[nn])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN multi-layer + zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if RUN_CNNM:\n",
    "    nn = 'CNNM_ZEROS'\n",
    "    trials_out[nn] = trial(nn=nn, N_range=N_RANGE, random_states=RANDOM_STATES)\n",
    "    debug_summary(trials_out[nn])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot log(N) vs sqrt_mse (all trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sqrt_mse(plot_std=False):\n",
    "    \n",
    "    plt.figure(figsize=(15, 4))\n",
    "    \n",
    "    ax1 = plt.subplot(1, 2, 1)\n",
    "\n",
    "    ax1.set(title='sqrt_mse', xlabel='log(N)', ylabel='sqrt_mse')\n",
    "\n",
    "    colors = iter(cm.rainbow(np.linspace(0, 1, len(trials_out))))\n",
    "\n",
    "    for trial in trials_out:\n",
    "        out = trials_out[trial]\n",
    "        x = np.log10(out['a_N'])\n",
    "        y = out['a_sqrt_mse']\n",
    "        c = next(colors)\n",
    "        ax1.plot(x, y, linewidth=0.5, c=c, marker='o', markersize=3, label=trial)\n",
    "        if plot_std:\n",
    "            std = out['a_std_abs_errors']\n",
    "            ax1.fill_between(x, y - std, y + std, facecolor=colors[i], alpha=0.3)\n",
    "    \n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "plot_sqrt_mse()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print and save statistics (yulesimon.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list = []\n",
    "for trial in trials_out:\n",
    "    t = trials_out[trial]\n",
    "    dict_list.append(('N', t['a_N']))\n",
    "for trial in trials_out:\n",
    "    t = trials_out[trial]\n",
    "    dict_list.append(('sqrt_mse_{}'.format(trial), t['a_sqrt_mse']))\n",
    "for trial in trials_out:\n",
    "    t = trials_out[trial]\n",
    "    dict_list.append(('std_{}'.format(trial), t['a_std_abs_errors']))\n",
    "for trial in trials_out:\n",
    "    t = trials_out[trial]\n",
    "    dict_list.append(('avg_abs_error_{}'.format(trial), t['a_avg_abs_errors']))\n",
    "\n",
    "df = pd.DataFrame(dict(dict_list))\n",
    "\n",
    "df = df.set_index('N')\n",
    "\n",
    "df.to_csv('yulesimon.csv', float_format='%.5f')\n",
    "\n",
    "columns=[]\n",
    "for t in trials_out:\n",
    "    columns.append(('sqrt_MSE', trial))\n",
    "for t in trials_out:\n",
    "    columns.append(('STD', trial))\n",
    "for t in trials_out:\n",
    "    columns.append(('avg_abs_err', trial))\n",
    "\n",
    "df.columns=pd.MultiIndex.from_tuples(columns)\n",
    "\n",
    "print('err = y_test - y_pred')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $mse$ comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list_mse = []\n",
    "for trial in trials_out:\n",
    "    t = trials_out[trial]\n",
    "    dict_list_mse.append(('N', t['a_N']))\n",
    "    dict_list_mse.append((f'{trial}', t['a_sqrt_mse']))\n",
    "\n",
    "df = pd.DataFrame(dict(dict_list_mse))\n",
    "\n",
    "df = df.set_index('N')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $STD$ comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list_std = []\n",
    "for trial in trials_out:\n",
    "    t = trials_out[trial]\n",
    "    dict_list_std.append(('N', t['a_N']))\n",
    "    dict_list_std.append((f'{trial}', t['a_std_abs_errors']))\n",
    "\n",
    "df = pd.DataFrame(dict(dict_list_std))\n",
    "\n",
    "df = df.set_index('N')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, p = model_compare(nn1='DNN', nn2='CNN', num_tests=TTEST_NUM_TESTS, N_pow=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t, p = model_compare(nn1='DNN', nn2='CNN', num_tests=5, N_pow=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t, p = model_compare(nn1='DNN', nn2='CNN', num_tests=5, N_pow=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t, p = model_compare(nn1='DNN', nn2='CNN', num_tests=5, N_pow=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t, p = model_compare(nn1='DNN', nn2='CNN', num_tests=5, N_pow=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t, p = model_compare(nn1='DNN', nn2='DNN_ZEROS', num_tests=TTEST_NUM_TESTS, N_pow=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t, p = model_compare(nn1='DNN', nn2='DNN_ZEROS', num_tests=5, N_pow=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t, p = model_compare(nn1='CNN', nn2='CNN_ZEROS', num_tests=TTEST_NUM_TESTS, N_pow=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t, p = model_compare(nn1='CNN', nn2='CNN_ZEROS', num_tests=5, N_pow=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t, p = model_compare(nn1='CNN', nn2='CNNM', num_tests=TTEST_NUM_TESTS, N_pow=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t, p = model_compare(nn1='CNN', nn2='CNNM', num_tests=5, N_pow=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ou",
   "language": "python",
   "name": "ou"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
